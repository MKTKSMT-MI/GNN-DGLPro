{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from dgl.nn import GraphConv,SAGEConv\n",
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import datetime\n",
    "from modules import ICPKGIDataset\n",
    "from models import PatchGCN,MultiPatchGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nデータセットを読み込む\\nデータローダーをシャッフルで作成\\nモデルにデータを入力\\n1epoch終了後各物体の視線方向ごとのデータを入力し中間層の出力を得る\\n出力の特徴マップを同じ位置のノードごとの平均をとってその方向の特徴グラフとする\\nテストデータを同様の手順で処理し特徴グラフを取得する。ただしそれぞれのデータで行う\\n学習における分類精度と特徴グラフによる分類精度を計算し保存する\\n分類学習における予測と正解を用いて損失を計算しネットワークを更新する\\nすべてのテストデータに対して行ったのち全epochについて行う\\nこのファイルは1種類の物体について分類を行うファイルとする\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "データセットを読み込む\n",
    "データローダーをシャッフルで作成\n",
    "モデルにデータを入力\n",
    "1epoch終了後各物体の視線方向ごとのデータを入力し中間層の出力を得る\n",
    "出力の特徴マップを同じ位置のノードごとの平均をとってその方向の特徴グラフとする\n",
    "テストデータを同様の手順で処理し特徴グラフを取得する。ただしそれぞれのデータで行う\n",
    "学習における分類精度と特徴グラフによる分類精度を計算し保存する\n",
    "分類学習における予測と正解を用いて損失を計算しネットワークを更新する\n",
    "すべてのテストデータに対して行ったのち全epochについて行う\n",
    "このファイルは1種類の物体について分類を行うファイルとする\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "object_name = 'airplane'  #car bus airplane\n",
    "setting_file = \"config2.yaml\"\n",
    "\n",
    "#データ読み込み\n",
    "dataset=ICPKGIDataset(f'../data/ICPKGI/8patch_gray_{object_name}.dgl')\n",
    "\n",
    "#各クラスから均等に10個ずつテスト用として抜き出しtrainデータセットとtestデータセットを作成\n",
    "labels=[i.item() for _,i in dataset]\n",
    "traindataset, testdataset, trainlabels, testlabels=train_test_split(dataset,labels,test_size=0.2,shuffle=True,stratify=labels)\n",
    "\n",
    "#データローダー作成\n",
    "traindataloader=GraphDataLoader(traindataset,batch_size=16,shuffle=True,num_workers = 0,pin_memory = True)\n",
    "testdataloader=GraphDataLoader(testdataset,batch_size=10,shuffle=True,num_workers = 0,pin_memory = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=1024, num_edges=6720,\n",
      "      ndata_schemes={'f': Scheme(shape=(1, 32, 32), dtype=torch.float32)}\n",
      "      edata_schemes={}) tensor([0, 0, 0, 3, 3, 2, 3, 4, 3, 0, 0, 4, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for i,(g,d) in enumerate(traindataloader):\n",
    "    break\n",
    "print(g,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchGCN(\n",
       "  (input_layer): SAGEConv(\n",
       "    (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc_neigh): Linear(in_features=1024, out_features=8, bias=False)\n",
       "    (fc_self): Linear(in_features=1024, out_features=8, bias=True)\n",
       "  )\n",
       "  (middle_layers): ModuleList()\n",
       "  (output_layer): GraphConv(in=8, out=5, normalization=both, activation=None)\n",
       "  (m): LeakyReLU(negative_slope=0.01)\n",
       "  (flatt): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#設定ファイル読み込み\n",
    "with open(f'./configs/{setting_file}','r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "#モデルの初期化\n",
    "model=PatchGCN(1024,[8],5,embedding=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "emb_graphs=[]\n",
    "emb_labels=[]\n",
    "for i,(batched_graph,labels) in enumerate(traindataloader):\n",
    "    emb_labels.extend(labels.tolist())\n",
    "    batched_graph = batched_graph.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    pred,emb = model(batched_graph,batched_graph.ndata['f'])\n",
    "    emb_graphs.extend(dgl.unbatch(emb))\n",
    "    if i == 1:\n",
    "        break\n",
    "print(i)\n",
    "test_emb_graphs=[]\n",
    "test_emb_labels=[]\n",
    "#テスト\n",
    "model.eval()\n",
    "for tbatched_graph, tlabels in testdataloader:\n",
    "    test_emb_labels.extend(tlabels.tolist())\n",
    "    tbatched_graph = tbatched_graph.to(device)\n",
    "    tlabels = tlabels.to(device)\n",
    "    tpred,temb = model(tbatched_graph, tbatched_graph.ndata['f'])\n",
    "    test_emb_graphs.extend(dgl.unbatch(temb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\n"
     ]
    }
   ],
   "source": [
    "print(len(test_emb_graphs))\n",
    "stack_test_emb = torch.stack([g.ndata['emb'].to('cpu') for g in test_emb_graphs],dim=0).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([559, 1, 64, 8])\n"
     ]
    }
   ],
   "source": [
    "print(stack_test_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Graph(num_nodes=64, num_edges=420,\n",
      "      ndata_schemes={'f': Scheme(shape=(1, 32, 32), dtype=torch.float32), 'emb': Scheme(shape=(8,), dtype=torch.float32), 'h': Scheme(shape=(5,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=64, num_edges=420,\n",
      "      ndata_schemes={'f': Scheme(shape=(1, 32, 32), dtype=torch.float32), 'emb': Scheme(shape=(8,), dtype=torch.float32), 'h': Scheme(shape=(5,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=64, num_edges=420,\n",
      "      ndata_schemes={'f': Scheme(shape=(1, 32, 32), dtype=torch.float32), 'emb': Scheme(shape=(8,), dtype=torch.float32), 'h': Scheme(shape=(5,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=64, num_edges=420,\n",
      "      ndata_schemes={'f': Scheme(shape=(1, 32, 32), dtype=torch.float32), 'emb': Scheme(shape=(8,), dtype=torch.float32), 'h': Scheme(shape=(5,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=64, num_edges=420,\n",
      "      ndata_schemes={'f': Scheme(shape=(1, 32, 32), dtype=torch.float32), 'emb': Scheme(shape=(8,), dtype=torch.float32), 'h': Scheme(shape=(5,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=64, num_edges=420,\n",
      "      ndata_schemes={'f': Scheme(shape=(1, 32, 32), dtype=torch.float32), 'emb': Scheme(shape=(8,), dtype=torch.float32), 'h': Scheme(shape=(5,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=64, num_edges=420,\n",
      "      ndata_schemes={'f': Scheme(shape=(1, 32, 32), dtype=torch.float32), 'emb': Scheme(shape=(8,), dtype=torch.float32), 'h': Scheme(shape=(5,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=64, num_edges=420,\n",
      "      ndata_schemes={'f': Scheme(shape=(1, 32, 32), dtype=torch.float32), 'emb': Scheme(shape=(8,), dtype=torch.float32), 'h': Scheme(shape=(5,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=64, num_edges=420,\n",
      "      ndata_schemes={'f': Scheme(shape=(1, 32, 32), dtype=torch.float32), 'emb': Scheme(shape=(8,), dtype=torch.float32), 'h': Scheme(shape=(5,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=64, num_edges=420,\n",
      "      ndata_schemes={'f': Scheme(shape=(1, 32, 32), dtype=torch.float32), 'emb': Scheme(shape=(8,), dtype=torch.float32), 'h': Scheme(shape=(5,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=64, num_edges=420,\n",
      "      ndata_schemes={'f': Scheme(shape=(1, 32, 32), dtype=torch.float32), 'emb': Scheme(shape=(8,), dtype=torch.float32), 'h': Scheme(shape=(5,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=64, num_edges=420,\n",
      "      ndata_schemes={'f': Scheme(shape=(1, 32, 32), dtype=torch.float32), 'emb': Scheme(shape=(8,), dtype=torch.float32), 'h': Scheme(shape=(5,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=64, num_edges=420,\n",
      "      ndata_schemes={'f': Scheme(shape=(1, 32, 32), dtype=torch.float32), 'emb': Scheme(shape=(8,), dtype=torch.float32), 'h': Scheme(shape=(5,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=64, num_edges=420,\n",
      "      ndata_schemes={'f': Scheme(shape=(1, 32, 32), dtype=torch.float32), 'emb': Scheme(shape=(8,), dtype=torch.float32), 'h': Scheme(shape=(5,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=64, num_edges=420,\n",
      "      ndata_schemes={'f': Scheme(shape=(1, 32, 32), dtype=torch.float32), 'emb': Scheme(shape=(8,), dtype=torch.float32), 'h': Scheme(shape=(5,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=64, num_edges=420,\n",
      "      ndata_schemes={'f': Scheme(shape=(1, 32, 32), dtype=torch.float32), 'emb': Scheme(shape=(8,), dtype=torch.float32), 'h': Scheme(shape=(5,), dtype=torch.float32)}\n",
      "      edata_schemes={})]\n"
     ]
    }
   ],
   "source": [
    "unbatch_emb=dgl.unbatch(emb)\n",
    "print(unbatch_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 8])\n",
      "tensor([3, 1, 0, 4, 3, 3, 2, 2, 2, 1, 4, 4, 0, 3, 4, 4], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "print(unbatch_emb[0].ndata['emb'].shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n",
      "[4, 0, 3, 3, 3, 2, 0, 3, 3, 1, 4, 3, 4, 3, 3, 3, 1, 3, 2, 3, 3, 3, 3, 3, 0, 2, 3, 3, 4, 4, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(emb_graphs))\n",
    "print(len(emb_labels))\n",
    "print(emb_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_graphs=torch.zeros(5,64,8) #中間層の出力のクラス特徴を保存するリスト\n",
    "direction_labels=[0]*5 #ラベル数が何枚あるかを示すリスト\n",
    "for i in emb_labels:\n",
    "    direction_labels[i]+=1\n",
    "for emb_graph,emb_label in zip(emb_graphs,emb_labels):\n",
    "    #中間層の出力をラベル数で割ってクラスインデックスに加算する\n",
    "    direction_graphs[emb_label]+=((emb_graph.ndata['emb'])/direction_labels[emb_label]).to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 64, 8])\n",
      "[3, 6, 1, 8, 14]\n"
     ]
    }
   ],
   "source": [
    "print(direction_graphs.shape)\n",
    "print(direction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i1=torch.randn(5,4,2)\n",
    "i2=torch.randn(10,1,4,2)\n",
    "cos=nn.CosineSimilarity(-1)\n",
    "out=cos(i1,i2)\n",
    "print(out.shape)\n",
    "#print(torch.sum(out,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.6558, -0.7974],\n",
      "          [-0.0419,  0.1725]],\n",
      "\n",
      "         [[ 0.5432, -0.0453],\n",
      "          [-0.8530,  0.2272]],\n",
      "\n",
      "         [[-0.8122,  0.0120],\n",
      "          [ 0.9431,  0.6192]],\n",
      "\n",
      "         [[ 0.2029, -0.6699],\n",
      "          [-0.4704,  0.9742]],\n",
      "\n",
      "         [[ 0.9992,  0.9900],\n",
      "          [ 0.9499, -0.9605]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1627, -0.9442],\n",
      "          [-0.0737,  0.6008]],\n",
      "\n",
      "         [[-0.0224,  0.8065],\n",
      "          [ 0.9075,  0.6445]],\n",
      "\n",
      "         [[ 0.3859,  0.8390],\n",
      "          [-0.9752,  0.9082]],\n",
      "\n",
      "         [[-0.6861,  0.2468],\n",
      "          [ 0.5691,  0.9706]],\n",
      "\n",
      "         [[-0.8302,  0.6658],\n",
      "          [-0.9796, -0.9822]]]])\n"
     ]
    }
   ],
   "source": [
    "print(out.reshape(2,5,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([559, 5, 64])\n",
      "tensor([63.1343, 63.3886, 61.6226, 63.4640, 63.4585],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "out1=cos(direction_graphs,stack_test_emb)\n",
    "print(out1.shape)\n",
    "emb_pred=torch.sum(out1,dim=-1)\n",
    "print(emb_pred[0])\n",
    "print((emb_pred.argmax(1)==torch.tensor(test_emb_labels)).sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: red;\">以下物体ごとの分類を行うコード</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "object_name = 'all'  #car bus airplane\n",
    "setting_file = \"config_all.yaml\"\n",
    "\n",
    "#データ読み込み\n",
    "dataset=ICPKGIDataset(f'../data/ICPKGI/8patch_gray_{object_name}.dgl')\n",
    "\n",
    "#各クラスから均等に2割りずつテスト用として抜き出しtrainデータセットとtestデータセットを作成\n",
    "labels=[i.item() for _,i in dataset]\n",
    "traindataset, testdataset, trainlabels, testlabels=train_test_split(dataset,labels,test_size=0.2,shuffle=True,stratify=labels)\n",
    "\n",
    "#データローダー作成\n",
    "traindataloader=GraphDataLoader(traindataset,batch_size=16,shuffle=True,num_workers = 0,pin_memory = True)\n",
    "testdataloader=GraphDataLoader(testdataset,batch_size=10,shuffle=True,num_workers = 0,pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=1024, num_edges=6720,\n",
      "      ndata_schemes={'d': Scheme(shape=(1,), dtype=torch.int64), 'f': Scheme(shape=(1, 32, 32), dtype=torch.float32)}\n",
      "      edata_schemes={}) tensor([2, 2, 0, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "for i,(g,d) in enumerate(traindataloader):\n",
    "    break\n",
    "print(g,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiPatchGCN(\n",
       "  (input_layer): SAGEConv(\n",
       "    (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc_neigh): Linear(in_features=1024, out_features=8, bias=False)\n",
       "    (fc_self): Linear(in_features=1024, out_features=8, bias=True)\n",
       "  )\n",
       "  (middle_layers): ModuleList()\n",
       "  (object_output_layer): GraphConv(in=8, out=5, normalization=both, activation=None)\n",
       "  (direction_output_layer): GraphConv(in=8, out=3, normalization=both, activation=None)\n",
       "  (m): LeakyReLU(negative_slope=0.01)\n",
       "  (flatt): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#モデルの初期化\n",
    "model=MultiPatchGCN(1024,[8],object_output_size=5,direction_output_size=3)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindataset[0][0].ndata['d'][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[398., 486., 398., 549., 401.],\n",
      "        [465., 471., 406., 541., 457.],\n",
      "        [462., 599., 394., 420., 433.]])\n"
     ]
    }
   ],
   "source": [
    "direction_labels=torch.zeros(3,5) #トレーニングデータにおける各物体各方向ごとのデータ数\n",
    "for g,i in traindataset:\n",
    "    direction_labels[i][g.ndata['d'][0].item()]+=1\n",
    "print(direction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "emb_graphs=[]\n",
    "emb_labels=[]\n",
    "for i,(batched_graph,labels) in enumerate(traindataloader):\n",
    "    emb_labels.extend(labels.tolist())\n",
    "    batched_graph = batched_graph.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    obj_pred,dir_pred,emb = model(batched_graph,batched_graph.ndata['f'])\n",
    "    emb_graphs.extend(dgl.unbatch(emb))\n",
    "    if i == 1:\n",
    "        break\n",
    "print(i)\n",
    "test_emb_graphs=[]\n",
    "test_emb_labels=[]\n",
    "#テスト\n",
    "model.eval()\n",
    "for tbatched_graph, tlabels in testdataloader:\n",
    "    test_emb_labels.extend(tlabels.tolist())\n",
    "    tbatched_graph = tbatched_graph.to(device)\n",
    "    tlabels = tlabels.to(device)\n",
    "    tobj_pred,tdir_pred,temb = model(tbatched_graph, tbatched_graph.ndata['f'])\n",
    "    test_emb_graphs.extend(dgl.unbatch(temb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=64, num_edges=420,\n",
      "      ndata_schemes={'d': Scheme(shape=(1,), dtype=torch.int64), 'f': Scheme(shape=(1, 32, 32), dtype=torch.float32), 'emb': Scheme(shape=(8,), dtype=torch.float32), 'oc': Scheme(shape=(5,), dtype=torch.float32), 'dc': Scheme(shape=(3,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "print(emb_graphs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_graphs=torch.zeros(3,5,64,8) #中間層の出力のクラス特徴を保存するリスト\n",
    "for emb_graph,emb_label in zip(emb_graphs,emb_labels):\n",
    "    #中間層の出力をラベル数で割ってクラスインデックスに加算する\n",
    "    dir_label=emb_graph.ndata['d'][0].item()\n",
    "    direction_graphs[emb_label][dir_label]+=((emb_graph.ndata['emb'])/direction_labels[emb_label][dir_label]).to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 64, 8])\n",
      "tensor([[398., 486., 398., 549., 401.],\n",
      "        [465., 471., 406., 541., 457.],\n",
      "        [462., 599., 394., 420., 433.]])\n"
     ]
    }
   ],
   "source": [
    "print(direction_graphs.shape)\n",
    "print(direction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1721, 1, 64, 8])\n"
     ]
    }
   ],
   "source": [
    "#テストデータの出力の埋め込み表現のみをスタックする\n",
    "stack_test_emb = torch.stack([g.ndata['emb'].to('cpu') for g in test_emb_graphs],dim=0).unsqueeze(1)\n",
    "print(stack_test_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1721, 5, 64])\n"
     ]
    }
   ],
   "source": [
    "cos=nn.CosineSimilarity(-1)\n",
    "out=cos(direction_graphs[0],stack_test_emb)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1721, 3, 5, 64])\n",
      "torch.Size([1721, 3, 5])\n",
      "tensor([[62.5373, 62.3928, 62.4814, 62.3599, 62.1956],\n",
      "        [ 0.0000,  0.0000, 61.3671, 62.0113,  0.0000],\n",
      "        [61.3048, 62.2262,  0.0000, 61.6954, 62.4865]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "emb_pred=torch.stack([cos(stack_test_emb,direction_graph) for direction_graph in direction_graphs],dim=1)\n",
    "print(emb_pred.shape)\n",
    "emb_pred=torch.sum(emb_pred,dim=-1)\n",
    "print(emb_pred.shape)\n",
    "print(emb_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6, 14,  8,  9],\n",
      "        [10, 11, 12, 13, 12]])\n",
      "torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "a=torch.arange(15).reshape(3,5)\n",
    "a[1,2]=14\n",
    "a[2,4]=12\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor(14),\n",
      "indices=tensor(1))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(torch.max(a,dim=1).values,dim=0))\n",
    "last_emb_pred=torch.max(torch.max(emb_pred,dim=2).values,dim=1).indices\n",
    "print(last_emb_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1507.,   49.,  165.])\n"
     ]
    }
   ],
   "source": [
    "b=torch.zeros(3)\n",
    "for i in last_emb_pred:\n",
    "    b[i]+=1\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DGL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
