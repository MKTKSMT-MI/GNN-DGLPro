{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#普通に逆伝搬で学習を行うネットワークで学習を行う\n",
    "#出力層に近い中間層の出力を埋め込み表現としてクラス分類を行う\n",
    "#そもそもの学習による分類精度も一応示す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from dgl.nn import GraphConv,SAGEConv\n",
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICPKGIDataset(DGLDataset):\n",
    "    def __init__(self,data_path,transforms=None):\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "        super().__init__(name='ICPKGI_gprah')\n",
    "    \n",
    "    def process(self):\n",
    "        GRAPHS, LABELS = dgl.load_graphs(self.data_path) #保存したグラーフデータの読み込み\n",
    "        self.graphs = GRAPHS #グラフリストを代入\n",
    "        self.labels = LABELS['label'] #ラベル辞書の値のみ代入\n",
    "        self.dim_nfeats=len(self.graphs[0].ndata['f'][0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transforms == None:\n",
    "            return self.graphs[idx], self.labels[idx]\n",
    "        else:\n",
    "            data=self.transforms(self.graphs[idx])\n",
    "            return data,self.labels[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "    \n",
    "\n",
    "class EmbeddingNetwork(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats, out_feats):\n",
    "        super(EmbeddingNetwork, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, hidden_feats, aggregator_type='mean')\n",
    "        self.conv2 = SAGEConv(hidden_feats, hidden_feats, aggregator_type='mean')\n",
    "        self.conv3 = SAGEConv(hidden_feats, out_feats, aggregator_type='mean')\n",
    "        '''self.conv1 = GraphConv(in_feats, hidden_feats)\n",
    "        self.conv2 = GraphConv(hidden_feats, hidden_feats)'''\n",
    "        self.flatt=nn.Flatten()\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        '''x=self.flatt(features)\n",
    "        x = torch.relu(self.conv1(g, x))\n",
    "        x = self.conv2(g, x)\n",
    "        #x = self.conv3(g,x)'''\n",
    "        \n",
    "        x = self.flatt(features)\n",
    "        x = torch.relu(self.conv1(g,x))\n",
    "        x = torch.relu(self.conv2(g,x))\n",
    "        x = self.conv3(g,x)\n",
    "\n",
    "        g.ndata['h'] = x\n",
    "        return g\n",
    "    \n",
    "\n",
    "class PatchGCN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size,liner=False,embedding = False):\n",
    "        super(PatchGCN,self).__init__()\n",
    "        self.embedding=embedding\n",
    "\n",
    "        self.input_layer=SAGEConv(input_size,hidden_size[0], aggregator_type='mean')\n",
    "        self.middle_layers=nn.ModuleList([GraphConv(hidden_size[i],hidden_size[i+1]) for i in range(len(hidden_size)-1)])\n",
    "        self.output_layer=GraphConv(hidden_size[-1],output_size)\n",
    "        if liner==True:\n",
    "            self.liner_on = True\n",
    "            self.liner_layers=nn.ModuleList([nn.Liner(hidden_size[i],hidden_size[i]) for i in range(len(hidden_size))])\n",
    "        else:\n",
    "            self.liner_on =False\n",
    "        self.m=nn.LeakyReLU()\n",
    "\n",
    "        self.flatt=nn.Flatten()\n",
    "\n",
    "    \n",
    "    def forward(self,g,n_feat,e_feat=None):\n",
    "        n_feat=self.flatt(n_feat)\n",
    "        h=self.input_layer(g,n_feat)\n",
    "        h=self.m(h)\n",
    "        for i,layer in enumerate(self.middle_layers):\n",
    "            if self.liner_on==True:\n",
    "                h=self.liner_layers[i](h)\n",
    "            h=layer(g,h)\n",
    "            h=self.m(h)\n",
    "        g.ndata['emb'] = h\n",
    "        h=self.output_layer(g,h)\n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        \n",
    "        if self.embedding:\n",
    "            return dgl.mean_nodes(g,'h'),dgl.mean_nodes(g,'emb')\n",
    "        else:\n",
    "            return dgl.mean_nodes(g,'h')\n",
    "    \n",
    "    \n",
    "def _train_test_split(data,data_num):\n",
    "    shuffle_data=random.sample(data,len(data))\n",
    "    return shuffle_data[:-data_num], shuffle_data[-data_num:]\n",
    "\n",
    "\n",
    "def TestAccPlot(data,dir):\n",
    "    data=np.array(data)\n",
    "    x=[j for j in range(data.shape[0])]\n",
    "    y=data\n",
    "\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot()\n",
    "    ax.plot(x,y)\n",
    "    ax.set_title('Test accuracy')\n",
    "    ax.set_xlabel('epochs')\n",
    "    ax.set_ylabel('accuracy')\n",
    "    ax.set_xlim(0,data.shape[0])\n",
    "    ax.set_ylim(0,1)\n",
    "    fig.savefig(f'{dir}/test_acc.jpg',dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def TrainAccPlot(data,dir):\n",
    "    data=np.array(data)\n",
    "    x=[j for j in range(data.shape[0])]\n",
    "    y=data\n",
    "\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot()\n",
    "    ax.plot(x,y)\n",
    "    ax.set_title('Train accuracy')\n",
    "    ax.set_xlabel('epochs')\n",
    "    ax.set_ylabel('accuracy')\n",
    "    ax.set_xlim(0,data.shape[0])\n",
    "    ax.set_ylim(0,1)\n",
    "    fig.savefig(f'{dir}/train_acc.jpg',dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def TrainLossPlot(data,dir):\n",
    "    data=np.array(data)\n",
    "    x=[j for j in range(data.shape[0])]\n",
    "    y=data\n",
    "\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot()\n",
    "    ax.plot(x,y)\n",
    "    ax.set_title('Train loss')\n",
    "    ax.set_xlabel('epochs')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.set_xlim(0,data.shape[0])\n",
    "    fig.savefig(f'{dir}/train_loss.jpg',dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def TrainTestAccPlot(traindata,testdata,dir):\n",
    "    traindata=np.array(traindata)\n",
    "    testdata=np.array(testdata)\n",
    "    x=[j for j in range(traindata.shape[0])]\n",
    "\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot()\n",
    "    ax.plot(x,traindata,label='Train accuracy')\n",
    "    ax.plot(x,testdata,label='Test accuracy')\n",
    "    ax.legend()\n",
    "\n",
    "    ax.set_title('Train & Test accuracy')\n",
    "    ax.set_xlabel('epochs')\n",
    "    ax.set_ylabel('accuracy')\n",
    "    ax.set_xlim(0,traindata.shape[0])\n",
    "    ax.set_ylim(0,1)\n",
    "    fig.savefig(f'{dir}/train_test_acc.jpg',dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "757\n"
     ]
    }
   ],
   "source": [
    "graphs=[[] for _ in range(5)]\n",
    "dataset=ICPKGIDataset('../data/ICPKGI/8patch_gray_car.dgl')\n",
    "labels=[i.item() for _,i in dataset]\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset, testdataset, trainlabels, testlabels=train_test_split(dataset,labels,shuffle=True,test_size=50,stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 352, 91, 198, 24]\n"
     ]
    }
   ],
   "source": [
    "cn=[0]*5\n",
    "for i,l in traindataset:\n",
    "    cn[l.item()]+=1\n",
    "print(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object name: car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.49787835926449786\n",
      "Test accuracy: 0.5\n",
      "Class 0: Accuracy 0.00%\n",
      "Class 1: Accuracy 100.00%\n",
      "Class 2: Accuracy 0.00%\n",
      "Class 3: Accuracy 0.00%\n",
      "Class 4: Accuracy 0.00%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "object_name = 'car'  #car bus airplane\n",
    "setting_file = \"config2.yaml\"\n",
    "\n",
    "#データ読み込み\n",
    "dataset=ICPKGIDataset(f'../data/ICPKGI/8patch_gray_{object_name}.dgl')\n",
    "\n",
    "#各クラスから均等に10個ずつテスト用として抜き出しtrainデータセットとtestデータセットを作成\n",
    "labels=[i.item() for _,i in dataset]\n",
    "traindataset, testdataset, trainlabels, testlabels=train_test_split(dataset,labels,test_size=50,shuffle=True,stratify=labels)\n",
    "\n",
    "#データローダー作成\n",
    "traindataloader=GraphDataLoader(traindataset,batch_size=256,shuffle=True,num_workers = 0,pin_memory = True)\n",
    "testdataloader=GraphDataLoader(testdataset,batch_size=10,shuffle=True,num_workers = 0,pin_memory = True)\n",
    "\n",
    "#設定ファイル読み込み\n",
    "with open(f'./configs/{setting_file}','r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "#パラメータ設定\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "\n",
    "print(f'object name: {object_name}')\n",
    "for model_name, model_config in config.items():\n",
    "    #時間計測\n",
    "    start=time.time()\n",
    "    #結果を保存するディレクトリを作成\n",
    "    #Classification/save\n",
    "    #save_dir=f'../Classification/save/{data_path[data_number]}/config1.yaml/{model_name}'\n",
    "    #save_dir=f'../../Classification/save/embedding/single class/{object_name}/{model_name}'\n",
    "    save_dir=f'./save/embedding/single class/{object_name}/{model_name}'\n",
    "    os.makedirs(save_dir,exist_ok=True)\n",
    "\n",
    "    #モデルの初期化\n",
    "    model=PatchGCN(model_config['input_size'],model_config['hidden_size'],model_config['output_size'])\n",
    "    model.to(device)\n",
    "    lossF=nn.CrossEntropyLoss()\n",
    "    optimizer=optim.AdamW(model.parameters(),lr=lr)\n",
    "\n",
    "    #情報保存用の変数の初期化\n",
    "    #トレーニング用\n",
    "    num_correct=0\n",
    "    num_tests=0\n",
    "    loss_correct=0\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    #テスト用\n",
    "    test_num_correct = 0\n",
    "    test_num_tests = 0\n",
    "    best_acc=0\n",
    "    test_acc_list = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        #トレーニング\n",
    "        model.train()\n",
    "        for i,(batched_graph, labels) in enumerate(traindataloader):\n",
    "            batched_graph = batched_graph.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            pred = model(batched_graph, batched_graph.ndata['f'])\n",
    "            loss = lossF(pred,labels)\n",
    "            loss_correct += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "            num_tests += len(labels)\n",
    "        train_loss_list.append(loss_correct / (i+1))\n",
    "        train_acc_list.append(num_correct / num_tests)\n",
    "        #カウントリセット\n",
    "        num_correct=num_tests=loss_correct=0\n",
    "\n",
    "        #テスト\n",
    "        model.eval()\n",
    "        for tbatched_graph, tlabels in testdataloader:\n",
    "            tbatched_graph = tbatched_graph.to(device)\n",
    "            tlabels = tlabels.to(device)\n",
    "            tpred = model(tbatched_graph, tbatched_graph.ndata['f'])\n",
    "            tpred = F.softmax(tpred,dim=1)\n",
    "            test_num_correct += (tpred.argmax(1) == tlabels).sum().item()\n",
    "            test_num_tests += len(tlabels)\n",
    "\n",
    "        test_acc_list.append(test_num_correct/test_num_tests)\n",
    "        if best_acc < test_num_correct/test_num_tests:\n",
    "            best_acc = test_num_correct/test_num_tests\n",
    "            best_weight = model\n",
    "        #カウントリセット\n",
    "        test_num_correct=test_num_tests=0\n",
    "\n",
    "    #完全学習後の正答率の計算(推論)\n",
    "    with torch.no_grad():\n",
    "        #情報保存用の変数の初期化\n",
    "        #トレーニング用\n",
    "        num_correct=0\n",
    "        num_tests=0\n",
    "        save_train_acc=0\n",
    "        #テスト用\n",
    "        test_num_correct = 0\n",
    "        test_num_tests = 0\n",
    "        save_test_acc=0\n",
    "\n",
    "        #全トレーニングデータでの正答率計算\n",
    "        model.train()\n",
    "        for batched_graph, labels in traindataloader:\n",
    "            batched_graph = batched_graph.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred = model(batched_graph, batched_graph.ndata['f'])\n",
    "            num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "            num_tests += len(labels)\n",
    "        print('Training accuracy:', num_correct / num_tests)\n",
    "        save_train_acc=(num_correct / num_tests)\n",
    "\n",
    "        #全テストデータでの正答率\n",
    "        model.eval()\n",
    "        correct_by_class = [0]*5\n",
    "        total_by_class = [0]*5\n",
    "        for batched_graph, labels in testdataloader:\n",
    "            batched_graph = batched_graph.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred=model(batched_graph, batched_graph.ndata['f'])\n",
    "            pred = F.softmax(pred,dim=1)\n",
    "            predicted_labels = pred.argmax(1)\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                true_label = labels[i].item()\n",
    "                predicted_label = predicted_labels[i].item()\n",
    "                total_by_class[true_label] += 1\n",
    "                if true_label == predicted_label:\n",
    "                    correct_by_class[true_label]+=1\n",
    "            test_num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "            test_num_tests += len(labels)\n",
    "        print('Test accuracy:', test_num_correct / test_num_tests)\n",
    "        class_accuracy = [correct_by_class[i] / total_by_class[i] if total_by_class[i] > 0 else 0 for i in range(5)]\n",
    "        for i in range(5):\n",
    "            print(f'Class {i}: Accuracy {class_accuracy[i]:.2%}')\n",
    "        save_test_acc=(test_num_correct / test_num_tests)\n",
    "\n",
    "    #各エポックごとの損失・正答率の記録をモデルごとに.npy形式で保存\n",
    "    np.save(f'{save_dir}/train_loss_list',train_loss_list)\n",
    "    np.save(f'{save_dir}/train_acc_list',train_acc_list)\n",
    "    np.save(f'{save_dir}/test_acc_list',test_acc_list)\n",
    "    torch.save(model,f'{save_dir}/model_weight.pth')\n",
    "    torch.save(best_weight,f'{save_dir}/best_model_weight.pth')\n",
    "    #保存したnpyを画像にプロット＆保存\n",
    "    TrainAccPlot(train_acc_list,save_dir)\n",
    "    TrainLossPlot(train_loss_list,save_dir)\n",
    "    TestAccPlot(test_acc_list,save_dir)\n",
    "    TrainTestAccPlot(train_acc_list,test_acc_list,save_dir)\n",
    "    #完全学習後のトレーニング・テストデータそれぞれの正答率を.yaml形式で保存\n",
    "    log={'train acc':save_train_acc,\n",
    "        'test acc':save_test_acc,\n",
    "        'epochs':epochs,\n",
    "        'config':model_config,\n",
    "        'best test acc':best_acc,\n",
    "        'date time':datetime.datetime.now(),\n",
    "        'run time':time.time() - start}\n",
    "        \n",
    "    with open(f'{save_dir}/acc_result.yaml',\"w\") as f:\n",
    "        yaml.dump(log,f)\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0728, 0.4364, 0.1606, 0.2855, 0.0447],\n",
      "        [0.0833, 0.4252, 0.1669, 0.2735, 0.0510],\n",
      "        [0.1395, 0.3116, 0.1902, 0.2475, 0.1112],\n",
      "        [0.0426, 0.5232, 0.1300, 0.2837, 0.0204],\n",
      "        [0.0142, 0.6485, 0.0772, 0.2554, 0.0047],\n",
      "        [0.0720, 0.4509, 0.1531, 0.2819, 0.0420],\n",
      "        [0.0539, 0.4914, 0.1417, 0.2863, 0.0267],\n",
      "        [0.0521, 0.5093, 0.1356, 0.2773, 0.0257],\n",
      "        [0.0681, 0.4539, 0.1561, 0.2849, 0.0370],\n",
      "        [0.1246, 0.3429, 0.1905, 0.2541, 0.0878]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:1')\n",
      "tensor([3, 3, 3, 2, 1, 0, 1, 1, 1, 2], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "print(pred.argmax(1))\n",
    "print(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DGL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
