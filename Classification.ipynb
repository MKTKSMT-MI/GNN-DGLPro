{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echigo/anaconda3/envs/DGL2/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.data\n",
    "from dgl.nn import GraphConv\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#トレーニング用データセットクラス\n",
    "class CIFAR10TrainDataset(DGLDataset):\n",
    "    def __init__(self,data_path):\n",
    "        self.data_path = data_path\n",
    "        super().__init__(name='cifar10_train__gprah')\n",
    "    \n",
    "    def process(self):\n",
    "        GRAPHS, LABELS = dgl.load_graphs(self.data_path) #保存したグラーフデータの読み込み\n",
    "        self.graphs = GRAPHS #グラフリストを代入\n",
    "        self.labels = LABELS['label'] #ラベル辞書の値のみ代入\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "\n",
    "class CIFAR10TestDataset(DGLDataset):\n",
    "    def __init__(self,data_path):\n",
    "        self.data_path = data_path\n",
    "        super().__init__(name='cifar10_test_gprah')\n",
    "    \n",
    "    def process(self):\n",
    "        GRAPHS, LABELS = dgl.load_graphs(self.data_path) #保存したグラーフデータの読み込み\n",
    "        self.graphs = GRAPHS #グラフリストを代入\n",
    "        self.labels = LABELS['label'] #ラベル辞書の値のみ代入\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/MyDataset/train_graphs_six_f_in_pos_50_std.dgl\"\n",
    "traindataset = CIFAR10TrainDataset(\"./data/MyDataset/train_graphs_six_f_in_pos_40_std.dgl\")\n",
    "testdataset = CIFAR10TestDataset(\"./data/MyDataset/test_graphs_six_f_in_pos_40_std.dgl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_wokers = 2\n",
      "posix\n"
     ]
    }
   ],
   "source": [
    "if os.name =='posix':\n",
    "    num_workers = 2\n",
    "else:\n",
    "    num_workers = 0\n",
    "#num_workers = 0\n",
    "traindataloader = GraphDataLoader(traindataset,batch_size = 2500,shuffle = True,num_workers = num_workers,pin_memory = True)\n",
    "testdataloader = GraphDataLoader(testdataset,batch_size = 5000,shuffle = True,num_workers = num_workers,pin_memory = True)\n",
    "print(f'num_wokers = {num_workers}')\n",
    "print(os.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8])\n",
      "tensor([1.6716, 2.1639, 0.0000, 0.0000, 1.4623, 1.4378, 7.0000, 9.0000])\n",
      "tensor([3.7305, 0.6879, 0.0000, 0.0000, 0.9180, 1.6218, 9.0000, 8.0000])\n",
      "tensor([ 3.5519,  0.0313,  0.0164,  0.0000,  1.1322,  2.8422, 10.0000,  8.0000])\n",
      "tensor([2.1775, 1.1634, 0.0000, 0.0000, 1.8922, 2.5067, 9.0000, 7.0000])\n",
      "tensor([ 2.0353,  1.6321,  0.0000,  0.0000,  1.5512,  2.6334, 10.0000,  7.0000])\n",
      "Dataset(\"cifar10_train__gprah\", num_graphs=10000, save_path=/home/makoto/.dgl/cifar10_train__gprah)\n"
     ]
    }
   ],
   "source": [
    "print(traindataset[0][0].ndata['feat value'].shape)\n",
    "for i in range(5):\n",
    "    print(traindataset[3][0].ndata['feat value'][i])\n",
    "print(traindataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(\"cifar10_train__gprah\", num_graphs=10000, save_path=/home/makoto/.dgl/cifar10_train__gprah)\n",
      "torch.Size([5, 8])\n",
      "tensor([1.6716, 2.1639, 0.0000, 0.0000, 1.4623, 1.4378, 7.0000, 9.0000])\n",
      "tensor([3.7305, 0.6879, 0.0000, 0.0000, 0.9180, 1.6218, 9.0000, 8.0000])\n",
      "tensor([ 3.5519,  0.0313,  0.0164,  0.0000,  1.1322,  2.8422, 10.0000,  8.0000])\n",
      "tensor([2.1775, 1.1634, 0.0000, 0.0000, 1.8922, 2.5067, 9.0000, 7.0000])\n",
      "tensor([ 2.0353,  1.6321,  0.0000,  0.0000,  1.5512,  2.6334, 10.0000,  7.0000])\n"
     ]
    }
   ],
   "source": [
    "print(traindataset)\n",
    "print(traindataset[0][0].ndata['feat value'].shape)\n",
    "for i in range(5):\n",
    "    print(traindataset[3][0].ndata['feat value'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ネットワーク設定\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN,self).__init__()\n",
    "        self.conv1 = GraphConv(8,16)\n",
    "        self.conv2 = GraphConv(16,32)\n",
    "        self.conv3 = GraphConv(32,128)\n",
    "        self.conv4 = GraphConv(64,128)\n",
    "        self.dropout =nn.Dropout(0.4)\n",
    "        self.meanpooling = nn.AvgPool1d(2)\n",
    "        self.maxpooling = nn.MaxPool1d(2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64,128)\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        self.fc3 = nn.Linear(64,32)\n",
    "        self.fc4 = nn.Linear(32,10)\n",
    "\n",
    "\n",
    "    def forward(self,g,n_feat,e_feat = None):\n",
    "        h = self.conv1(g,n_feat,None,e_feat)\n",
    "        h = self.conv2(g,h,None,e_feat)\n",
    "        #h = self.dropout(h)\n",
    "        h = self.conv3(g,h,None,e_feat)\n",
    "\n",
    "        #h = self.meanpooling(h)\n",
    "        h = self.maxpooling(h)\n",
    "\n",
    "        h = self.flatten(h)\n",
    "\n",
    "        h = F.relu(self.fc1(h))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.fc2(h))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.fc3(h))\n",
    "        h = self.fc4(h)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        return dgl.mean_nodes(g,'h')\n",
    "        #return dgl.softmax_nodes(g,'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling = nn.MaxPool1d(2)\n",
    "pooling2 = nn.MaxPool2d(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix = torch.rand(12500,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7619, 0.7089, 0.7608, 0.8669],\n",
      "        [0.0991, 0.6621, 0.4507, 0.0979],\n",
      "        [0.0647, 0.8731, 0.7839, 0.6762],\n",
      "        [0.7024, 0.3853, 0.8371, 0.1841]])\n"
     ]
    }
   ],
   "source": [
    "print(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7728, 0.2234, 0.9856,  ..., 0.3988, 0.5083, 0.8670],\n",
      "        [0.6787, 0.9461, 0.3916,  ..., 0.5052, 0.3915, 0.7855],\n",
      "        [0.9810, 0.9118, 0.3153,  ..., 0.3933, 0.4173, 0.7161],\n",
      "        ...,\n",
      "        [0.5828, 0.3772, 0.8316,  ..., 0.6934, 0.9974, 0.5197],\n",
      "        [0.1860, 0.7911, 0.2553,  ..., 0.7064, 0.8821, 0.9697],\n",
      "        [0.6617, 0.7005, 0.9893,  ..., 0.9502, 0.3999, 0.9248]])\n"
     ]
    }
   ],
   "source": [
    "print(pooling(test_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 32 64 128 x4 '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.02)\n",
    "#optimizer = optim.SGD(params=model.parameters(),lr=0.03,momentum=0.9)\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_train_acc = []\n",
    "save_test_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12500, 8])\n",
      "conv1:torch.Size([12500, 16])\n",
      "conv2:torch.Size([12500, 32])\n",
      "meanpooling:torch.Size([12500, 1])\n",
      "flatten:torch.Size([12500, 1])\n",
      "fc1:torch.Size([12500, 60])\n",
      "fc2:torch.Size([12500, 10])\n",
      "tensor(2.3248, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "conv1 = GraphConv(8,16)\n",
    "conv2 = GraphConv(16,32)\n",
    "conv3 = GraphConv(32,10)\n",
    "conv4 = GraphConv(64,128)\n",
    "dropout =nn.Dropout(0.2)\n",
    "meanpooling = nn.AvgPool1d(32)\n",
    "flatten = nn.Flatten()\n",
    "fc1 = nn.Linear(1,60)\n",
    "fc2 = nn.Linear(60,10)\n",
    "for i,p in traindataloader:\n",
    "    h = i.ndata['feat value'].float()\n",
    "    print(i.ndata['feat value'].float().shape)\n",
    "    h = conv1(i,h)\n",
    "    print(f'conv1:{h.shape}')\n",
    "    h = conv2(i,h)\n",
    "    print(f'conv2:{h.shape}')\n",
    "    h = meanpooling(h)\n",
    "    print(f'meanpooling:{h.shape}')\n",
    "    h = flatten(h)\n",
    "    print(f'flatten:{h.shape}')\n",
    "    h = fc1(h)\n",
    "    print(f'fc1:{h.shape}')\n",
    "    h = fc2(h)\n",
    "    print(f'fc2:{h.shape}')\n",
    "    i.ndata['h'] = h\n",
    "    q = dgl.mean_nodes(i,'h')\n",
    "    break\n",
    "loss = F.cross_entropy(q,p)\n",
    "print(loss)\n",
    "print(loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.34045\n",
      "Test accuracy: 0.3182\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "test_num_correct = 0\n",
    "test_num_tests = 0\n",
    "#,batched_graph.edata['distance'].float()\n",
    "BP = 0\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    if BP != 0:\n",
    "        break\n",
    "    model.train()\n",
    "    for batched_graph, labels in traindataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat value'].float(),batched_graph.edata['distance'].float())\n",
    "        loss = F.cross_entropy(pred,labels)\n",
    "        if loss.item() < 0.05:\n",
    "            BP = 0\n",
    "            break\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "        num_tests += len(labels)\n",
    "    loss_list.append(loss.item())\n",
    "    acc_list.append(num_correct / num_tests)\n",
    "    \n",
    "    model.eval()\n",
    "    for tbatched_graph, tlabels in testdataloader:\n",
    "        tbatched_graph = tbatched_graph.to(device)\n",
    "        tlabels = tlabels.to(device)\n",
    "        tpred = model(tbatched_graph, tbatched_graph.ndata['feat value'],tbatched_graph.edata['distance'].float())\n",
    "        test_num_correct += (tpred.argmax(1) == tlabels).sum().item()\n",
    "        test_num_tests += len(tlabels)\n",
    "\n",
    "    Tacc = test_num_correct / test_num_tests\n",
    "    #print('Training accuracy:', Tacc)\n",
    "    #test_acc_list.append(Tacc)\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.train()\n",
    "    for batched_graph, labels in traindataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat value'],batched_graph.edata['distance'].float())\n",
    "        num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "        num_tests += len(labels)\n",
    "\n",
    "    print('Training accuracy:', num_correct / num_tests)\n",
    "    save_train_acc.append(num_correct / num_tests)\n",
    "\n",
    "    num_correct = 0\n",
    "    num_tests = 0\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    for batched_graph, labels in testdataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat value'].float(),batched_graph.edata['distance'].float())\n",
    "        num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "        num_tests += len(labels)\n",
    "\n",
    "    print('Test accuracy:', num_correct / num_tests)\n",
    "    save_test_acc.append(num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12500, 10])\n"
     ]
    }
   ],
   "source": [
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "tensor(2.3527, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#5:40\n",
    "#3:15\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA6aElEQVR4nO3deXicZbn48e89WSbLTPaZ7EubtOlGaUsKLZQd2UQQRAEVQVHEg0dR9IfiOepRjxuoHA8qVlY9Cqjs+1awLZSWtqT7krRN26TZ9319fn/M0iyTZukkk0zuz3Xl6uSdJ+/ceZPeeeZ+n0WMMSillJr+LIEOQCmllH9oQldKqSChCV0ppYKEJnSllAoSmtCVUipIaEJXSqkgoQldzSgi8oqI3DTOry0RkYv8HZNS/hIa6ACUGomItPT7NAroBHrdn3/ZGPPX0Z7LGHOZP2NTairRhK6mPGOMzfNYREqALxpj3hzcTkRCjTE9kxmbUlOJllzUtCUi54lIqYjcJSIVwCMiEi8iL4pItYjUux9n9Puad0Tki+7HN4vIehG51932kIiMqgcvIlYRuU9Ejrk/7hMRq/u5JPfrNohInYisExGL+7m7RKRMRJpFZJ+IXDgBl0bNUJrQ1XSXAiQA2cCtuH6nH3F/ngW0A/ef4OvPAPYBScAvgYdEREbxut8DVgBLgFOB04H/cD93J1AKOIBk4G7AiEg+8FVguTHGDlwClIzu21RqZJrQ1XTXB/zAGNNpjGk3xtQaY54yxrQZY5qB/wbOPcHXHzbG/MkY0ws8BqTiSsIj+QzwI2NMlTGmGvgv4Eb3c93u82QbY7qNMeuMa9GkXsAKLBCRMGNMiTHmwLi+a6V80ISuprtqY0yH5xMRiRKRP4rIYRFpAtYCcSISMszXV3geGGPa3A9tw7TtLw043O/zw+5jAPcAxcDrInJQRL7jPn8xcAfwQ6BKRJ4QkTSU8hNN6Gq6G7xc6J1APnCGMSYGOMd9fDRllLE4hqus45HlPoYxptkYc6cxZjZwJfBNT63cGPM3Y8wq99ca4Bd+jkvNYJrQVbCx46qbN4hIAvCDCXqdx4H/EBGHiCQB3wf+D0BErhCRPHctvhFXqaVPRPJF5AL3zdMOd5x9ExSfmoE0oatgcx8QCdQA7wOvTtDr/ATYDGwHdgBb3ccA5gBvAi3ABuD3xpi3cdXPf+6OrQJwAt+doPjUDCS6wYVSSgUH7aErpVSQ0ISulFJBQhO6UkoFCU3oSikVJAK2OFdSUpLJyckJ1MsrpdS0tGXLlhpjjMPXcwFL6Dk5OWzevDlQL6+UUtOSiBwe7jktuSilVJDQhK6UUkFCE7pSSgUJTehKKRUkNKErpVSQ0ISulFJBQhO6UkoFiWmX0PdVNPPfL+2mvas30KEopdSUMu0SellDG39ad4htpQ2BDkUppaaUaZfQl2XFA7DlcH2AI1FKqall2iX0uKhw5jhtfFBSF+hQlFJqSpl2CR2gICeerYfr6evT3ZaUUspjWib007ITaOrooaiqJdChKKXUlDEtE3pBtquOvvmwll2UUspjxIQuIpki8raI7BaRXSLydR9tPiMi20Vkh4i8JyKnTky4LtmJUSTZrHpjVCml+hnNeug9wJ3GmK0iYge2iMgbxpjd/docAs41xtSLyGXAauCMCYgXABEhzxlNaV37RL2EUkpNOyP20I0x5caYre7HzcAeIH1Qm/eMMZ7u8vtAhr8DHcxhj6C6pXOiX0YppaaNMdXQRSQHWApsPEGzW4BXhvn6W0Vks4hsrq6uHstLD+GwWalu1oSulFIeo07oImIDngLuMMY0DdPmfFwJ/S5fzxtjVhtjCowxBQ6Hzy3xRi3JHk5LZw9tXT0ndR6llAoWo0roIhKGK5n/1Rjz9DBtFgMPAlcZY2r9F6JvDpsVgJrmrol+KaWUmhZGM8pFgIeAPcaYXw/TJgt4GrjRGLPfvyH65rC7Enp1S8dkvJxSSk15oxnlchZwI7BDRArdx+4GsgCMMQ8A3wcSgd+78j89xpgCv0fbjzehax1dKaWAUSR0Y8x6QEZo80Xgi/4KajQ0oSul1EDTcqYoQGK0FYtoQldKKY9pm9BDLEJCtFXHoiullNu0TejgKrtoD10ppVw0oSulVJCY3gldZ4sqpZTX9E7odis1LV0YoxtdKKXUtE/oXb19NLXr9H+llJr2CR10tqhSSsE0T+gZ8ZEA7K/UreiUUmpaJ/RT0mOJDg/hvQM1gQ5FKaUCblon9LAQC6fPSuC94glf3FEppaa8aZ3QAc7KS+JgTSvljbodnVJqZpv2Cf3M3CQA7aUrpWa8aZ/Q56XYSYgO512toyulZrhpn9AtFmFJZhx7y5sDHYpSSgXUtE/oAOlxkZQ1aA1dKTWzjWYLukwReVtEdovILhH5uo8280Rkg4h0isi3JibU4aXHR9LY3k1Lp84YVUrNXKPpofcAdxpjFgArgNtFZMGgNnXA14B7/RzfqKTHuSYYldVrL10pNXONmNCNMeXGmK3ux83AHiB9UJsqY8wHQPeERDmCdPeM0bKGtkC8vFJKTQljqqGLSA6wFNg4nhcTkVtFZLOIbK6urh7PKXzy9tAbdE0XpdTMNeqELiI24CngDmNM03hezBiz2hhTYIwpcDgc4zmFTw6blfAQi5ZclFIz2qgSuoiE4UrmfzXGPD2xIY2dxSKkxkXoSBel1Iw2mlEuAjwE7DHG/HriQxqf9LhIyuq1hq6UmrlCR9HmLOBGYIeIFLqP3Q1kARhjHhCRFGAzEAP0icgdwILxlmbGIy0ukvVFOltUKTVzjZjQjTHrARmhTQWQ4a+gxiM9LpLK5g66evoIDw2K+VJKKTUmQZP50uMjMQYqGnWki1JqZgqahJ7hHrpYUtsa4EiUUiowgiahL86MIzIshJd3lAc6FKWUCoigSeg2aygfXZzKC9uO0apruiilZqCgSegA1y3PpLWrl5e0l66UmoGCKqEXZMcz2xHN01tLAx2KUkpNuqBK6CLC2XlJ7CprwhgT6HCUUmpSBVVCB8hLttPc2UNFkw5fVErNLEGX0Oc4bQAUVbYEOBKllJpcQZvQ91fqHqNKqZkl6BJ6os1KYnQ4xVXaQ1dKzSxBl9AB8pw2ijShK6VmmKBM6HOSbeyvbNaRLkqpGSU4E7rTTnNHD1XNnYEORSmlJk1wJvRkvTGqlJp5gjKhz0+JAWB7aWOAI1FKqckzmi3oMkXkbRHZLSK7ROTrPtqIiPxWRIpFZLuILJuYcEcnPjqcPKeNzSV1gQxDKaUm1Wh66D3AncaYBcAK4HYRWTCozWXAHPfHrcAf/BrlOBRkx7PlcD19fXpjVCk1M4yY0I0x5caYre7HzcAeIH1Qs6uAPxuX94E4EUn1e7RjUJCTQFNHjw5fVErNGGOqoYtIDrAU2DjoqXTgaL/PSxma9BGRW0Vks4hsrq6uHmOoY7M8Jx6A13dV8I0nC9lXoTdIlVLBbcRNoj1ExAY8BdxhjGkaz4sZY1YDqwEKCgomtBaSlRBFks3Kr97YD7gmG+Wn2CfyJZVSKqBG1UMXkTBcyfyvxpinfTQpAzL7fZ7hPhYwIsLK3ETCQoSIMAtHatsCGY5SSk240YxyEeAhYI8x5tfDNHse+Jx7tMsKoNEYE/Btg/7ryoW8esc5LEyL5XCdbh6tlApuoym5nAXcCOwQkUL3sbuBLABjzAPAy8DlQDHQBnze75GOQ0J0OAnR4WQlRLHpkA5hVEoFtxETujFmPSAjtDHA7f4Kyt8yE6J4trCMrp4+wkODci6VUkoF50zRwbITojAGyhraAx2KUkpNmBmR0LMSowA4XKt1dKVU8JoZCT3BldCP1ulIF6VU8JoRCd1pt2INtXBEE7pSKojNiIQuImQlRGlCV0oFtRmR0MFVdjlU00pvn+HJD47w3y/t1h2NlFJBZdRT/6e7UzPjeGtvFct+/AaN7d0AXHZKKsuy4gMcmVJK+ceM6aF/5bxc/uf6JZyVl8j3r1hARJiFp7aUBjospZTymxnTQw8LsXDVknSuWuJaBHJ7aQMvbDvGf16xgIiwkABHp5RSJ2/G9NAHu2ZZBk0dPby1pyrQoSillF/M2IR+Vl4SsZFhrC+e2HXZlVJqsszYhB5iERakxrC7XDe+UEoFhxmb0AEWpMWwr6KJXt13VCkVBGZ0Qp+fGkNHdx+HanSNF6XU9DejE/qC1BgAdpePa0c9pZSaUkazY9HDIlIlIjuHeT5eRJ4Rke0isklEFvk/zImR57QRFiLsPqYJXSk1/Y2mh/4ocOkJnr8bKDTGLAY+B/yPH+KaFOGhFvKcdu2hK6WCwogJ3RizFjjR/m0LgDXutnuBHBFJ9k94E29Bagy7jzXS3dvH/WuKuOBX79DY1h3osJRSasz8UUPfBlwDICKnA9lAhq+GInKriGwWkc3V1VNj/PeZuYnUtHRxxk/f4t7X93OwupX3D9UGOiyllBozfyT0nwNx7g2k/x34EOj11dAYs9oYU2CMKXA4HH546ZN3zbJ0HvxcATmJUXz5nNlYQy26obRSalo66bVcjDFNwOcBRESAQ8DBkz3vZBERLlqQzEULXFWiwqMNfFCiCV0pNf2cdA9dROJEJNz96ReBte4kPy2dMSuBnWWNtHT2BDoUpZQak9EMW3wc2ADki0ipiNwiIreJyG3uJvOBnSKyD7gM+PrEhTvxls9KoM/AlsP1gQ5FKaXGZMSSizHmhhGe3wDM9VtEAbYsK54Qi7DxYC3nzp0adX6llBqNGT1T1JdoayinZcXzxu5K3aJOKTWtaEL34WNL0iiqatEJR0qpaUUTug8fPSWVUIvwXOGxQIeilFKjpgndh4TocM6d6+D5wmO6tK5SatrQhD6Mq5elU9HUwZq9ukWdUmp60IQ+jEsWppCZEMn9bxfrzVGl1LSgCX0YYSEWvnJuHtuONrCuqAaA1s4eNhyo5ZkPS+nu7QtwhEopNdBJT/0PZp84LZ371xTxxT9v5vScBDYfrqOj25XII8NCuHRRaoAjVEqp47SHfgLW0BD+9qUVfKogg7KGdq5ZlsFDNxVgEXRzaaXUlKM99BHkJEXzk4+fMvBYYjT7KzShK6WmFu2hj0N+ip19lZrQlVJTiyb0cZibbKektpX2Lp/LviulVEBoQh+HeSl2jIHiqpZAh6KUUl6a0MchP8UOwN4KXetFKTV16E3RcchOjPZuVdfY3o011MLK3ETynPZAh6aUmsE0oY9DiEWYk2zjH1tKvceiw0N459vn47BbAxiZUmomGzGhi8jDwBVAlTFmkY/nY4H/A7Lc57vXGPOIvwOdaq4ryCQroZZ/v2AOvX2Gj//uXe59bR+hIcKRujb+cssZgQ5RKTXDjKaH/ihwP/DnYZ6/HdhtjPmYiDiAfSLyV2NMl59inJJuXJnDjStzvJ9/dkU2j75X4v28vLGdlJgIevoMYSGuWxVtXT28sqOCgpx4shOjJzlipVSwG/GmqDFmLVB3oiaAXUQEsLnbzrgdlr9+4RxOn5XA51ZmA1B4pIGH1h9i5c/WUNPSydr91az82Rru/Mc2/vDOgQBHq5QKRv6ood8PPA8cA+zAdcYYnytXicitwK0AWVlZfnjpqSM+Opy/f3klnT29PLHpKIVHG3j/YC01LZ384LldbDxUh8NuJTYyjGONHYEOVykVhPwxbPESoBBIA5YA94tIjK+GxpjVxpgCY0yBwxGcGzBbQ0OYnxbDW3ur2FbaiMNu5aUd5TS0dfE/1y9hXoqdisb2QIeplApC/kjonweeNi7FwCFgnh/OO20tzYzzTjq6/4alLEyL4a5L57EwLZaU2AjKtYeulJoA/ii5HAEuBNaJSDKQDxz0w3mnrSWZcQAkx1g5fVYCL33tbO9zKbERNHf00NrZQ7RVR40qpfxnNMMWHwfOA5JEpBT4ARAGYIx5APgx8KiI7AAEuMsYUzNhEU8DS7PiADg/34nrXvFxqbERAFQ0dZDrsE12aEqpIDZiQjfG3DDC88eAi/0WURDISojiO5fN4+IFyUOeS45xJfTKRk3oSin/0vf8E0BEuO3cXJ/PpcZGAmgdXSnld7o41yRLiTleclFKKX/ShD7JIsNDiI0Mo6Kxg2MN7eyraKarRzecVkqdPC25BEBqbASl9W1c/ft3qWzqxB4RymNfOJ1lWfGBDk0pNY1pDz0AUmIjWFdUQ2VTJ185L5f4qHBu/fMWynXCkVLqJGhCDwDPol0Ou5U7PzKXB28qoKO7l9v+skXLL0qpcdOEHgAp7rHon1iWQWiIhbnJdu795GK2lTbyrX9s4/rVG/ivF3YFOEql1HSjCT0A5jjthIdYuG55pvfYpYtSufnMHJ7fdoz3D9bx5AdHtbeulBoTvSkaAJctSuGM2ReQZBu4u9H3PjqfM3MTae/u5etPFLL1SD0rZicGKEql1HSjPfQAsFhkSDIHCAuxcPHCFM6f5yTEIqwvGvsKCruPNfG9Z3bQ0d3rj1CVUtOIJvQpKCYijCWZcawrqvb5fF+fGfZrX91VwV83HuFnL++ZqPCUUlOUJvQp6uw5SWwva+SpLaVsOlTnTeJNHd0s+dHrPFdY5vPrKt1LCjy24TBr9lZOWrxKqcDThD5FXTgvGWPgzn9s41N/3MD5v3qHo3VtFFU209TRwx//dRBjhvbUK5o6mJdiJ8kWzovbywMQuVIqUPSm6BR1SkYs6/7f+XT29FF4tIFv/WMbr+2qIC4qHIDd5U18eLRhyOzSyqYOMuKjiAoPoUIXAFNqRtEe+hSWmRBFntPGtadlkGQLZ39lM4dqWgi1CDZrKP/3/uEhX1PZ1EFKrJXUuEhN6ErNMJrQp4k5Tjv7K1s4VNNKVkIUVy9N58Vt5VT1W7Wxo7uX+rZuUmIiSI1xbXVnjOGdfVXsPtYUwOiVUpNhxIQuIg+LSJWI7Bzm+W+LSKH7Y6eI9IpIgv9DndnmJtsoqmzmYHUrOUnRfGHVLLr7+nj0vRIee6+ET/1xA5Xu5J4cE0FKbATt3b00tnfzrX9s4zdv7g/wd6CUmmijqaE/CtwP/NnXk8aYe4B7AETkY8A3jDF1/gpQucxJttPa1cu+ymbOyktiVlI0ly5M4ZF3S+jo6cUY2HTIddmTYyKICnf9aHeXN1HT0sWhmlYA6lq7CLEIsZFhAftelFITY8QeujFmLTDaBH0D8PhJRaR8mptsB8AYmJUUDcCt58ymvbsXh3uS0pt7XMMUU2IjSI1zrRfzXnEtAEdq2+jtM9zy2Afc/fSOyQ5fKTUJ/FZDF5Eo4FLgqRO0uVVENovI5upq35NmlG9zk4/vP+pJ6Euz4nnk5uU899WzCAsR1rlnlibHRHg3o15X7DrW1dvH4dpWdpY1sr+yeZKjV0pNBn/eFP0Y8O6Jyi3GmNXGmAJjTIHD4fDjSwe/uKhwHHZXT9yT0AHOn+ckNTaS/BQ7bV29RIaFEBMRisNmxSKwo7TB2/bNPZV09xpK69t9jmFXSk1v/kzo16Pllgk1N9lGRJjFuy9pf4vSYgFIjrEiIoSGWHDaI+gzkBDtGrv+8o4KANq7e6lr7Zq8wJVSk8IvCV1EYoFzgef8cT7l26cKMrnpzBwsFhny3MJ0T0I/nuw9dfQVsxOIDAuh8GiD97nSetfuSIdrWyn4yRvsq9AyjFLT3WiGLT4ObADyRaRURG4RkdtE5LZ+za4GXjfGtE5UoAquWpLOdy+b7/O5U9wJ3bN5BuCto+c5bGQnRgFgs7pGv3gS+hu7K6lp6WJnWaPP83Z09+oEJaWmiRGHLRpjbhhFm0dxDW9UATIvxU54qIXM+CjvsZSYSABynTZmVbWwt6KZc/MdvLS9nNL6NgA2HHCNgqlq7vR53u89s5PnCsv4f5fm88VVs32+O1BKTQ06UzRIRISF8PRXzuRLZ8/2HvP00HMdNnLcN1JPz0kgNjKMo/Vt9PT2sdE9dr2q+Xgv/KH1h7jxoY0crG7h2cIyEqLD+enLe3ly89FJ/I6UUmOlCT2ILEqPJTbq+IShjyxI5tNnZJGfYveOjJmfGkNGfCSl9e3sKGukpbMHgKqm4z30N3dXsq6ohk8+sAEBnrn9LJJs4Xx4pH5Svx+l1NjoaotBLCcpmp9efQoAHz0llY7uXgqy48mIj+RAdSvvucstc5y2AT30gzUtRIWHUNvaxdVL00mPiyTXYaOoqiUg34dSanS0hz5DRFtD+dxK1wiZzPgoSuvbeK6wjHkpdvJT7N4aenNHN5VNndx2bi7/ecUCvnvZPADmJNsormoZMH69u7ePR989NOzCXx3dvaxee4D2Lt0OT6nJoAl9BsqIj6Sju4/9lS186+J8kmMiqGrqxBjDwWrXQKX8FDu3rJqFM+b4SJnmjh6q3Ym/rrWLG1a/zw9f2M3v3in2+Trv7Kvmpy/v5c8bSibl+1JqptOEPgNlJx5fC+aiBck47Vbau3tp6ezhQLWrrJLrsA34mjynay2ZYnfZ5W8bD7P5cD2zkqLZU+67h360zjWS5k/rDumm1UpNAk3oM9DZc5J44LOn8e1L8gFwxriWFKhq7uRgdSshFiErIWrA1+Q5XQm+2J3wi6payIiP5MpT0yipafVZVjla34ZFoKalk8c3HfFb/IVHGzhcq1MelBpME/oMFBpi4dJFKYSFuH78TrurrFLV1MmB6hayE6IIDx34q5EcY8VuDaWo0pXQi6tayHXYmJ9qp8/gc8GvI3VtzE+N4fRZCfzXC7u5/W9b2XK4/qTWkenq6eOmhzfx6T9tpKmje9znUSoY6SgXhdPu6aF3cKC6hdmDyi0AIkKu03VjtK/PVWs/Y1Yi81NjANhT3sQbuys51tDOufkOrjw1jaN1bcxNtvPLaxfzp7UHeXD9IV7aXk6Szcq8FDs/u+YUMge9ExjJ+wdraWzvprG9m+8/u5P7rl968hdAqSChPXTl7aFXNHZQUtNGrjPaZ7s8p43i6haONbbT3t1LrjOazPgoosNDeHF7Ofe/XcxLO8r5+hOFfHi0gaP17WQlRGGPCOObF+ez8e4L+eUnFrMqL5H1xTX8a//Yl1B+ZWcFUeEh/Nt5uTxbeIxnPyw7qe9dqWCiCV0RExlKeKiFNXur6OrtG3JD1OOU9Fiqmzt5c7drI408hw2LRZiXGsP64hrCQy08/9VVALy0vZyunj4y+vXA7RFhfGp5Jr/+1BLCQoRjDe1jirO3z/DG7grOn+fkmx+ZS0F2PP/x7E7vzVelZjpN6AoRwWm3svFQHfFRYVyyIMVnu4sWJAOuUSvgWiMGYH6qawTMVaemeWelPlfo6jlnxkcOOY/FIqTERow5oW86VEdNSxeXLUohNMTCb65bggC/eHXvmM6jVLDShK6A43X0b16cP2D5gP7S4yJZlB5DWUM7sZFhJLrXWV+SGY9F4PNnzQKgIDuemhbXeuuDR8t4pMVGUuYjoW8uqfN5s9MYw2/e2E9CdDjn5zsByEyIYtWcJHYNM7FJqZlGE7oCYEFaDIszYrlheeYJ213s7r3nOW2IuFZevHppOmvuPI8Faa4bpMtzEgAQgXQfPXRw/XE41jBwWd59Fc1c+8AG/rLh8JD2L24vZ1NJHd++JJ9o6/F7+XlOG4drW+ns0XHuSmlCVwD8+KpFPP2VMwkNOfGvxMULXWWXXMfxG6chFvGu5giwfJYroafERGANDfF5nrS4SCqaOujp7fMe+9O6gwAUDRoC2dLZw09f3sPCtBg+VTDwD06e00afgZKaE9fRG9u6+b/3D9PYpkMdVfDSYYsKwL1t3chrnecn27n5zBwuWei7zg6QkxhFki18wNrsg6XFRdLbZzhS18ZPX97D3GS7t+5+qGbgpKF7X9tHRVMH9396GSGD1mP33MAtrmohP8Xu87We/bCMHzy/i8b2blo7e/jyubkjfp9KTUcjJnQReRi4Aqgyxiwaps15wH1AGFBjjDnXfyGqqURE+OGVC0fVxh7huxYPkObeHu/5bcd4c08Vb+6pwiJwXr7DO/lIRNh2tIHHNpRw08ocTsuOH3KeXIcNkeNLEgz29w+OctfT2ynIjqeoqkVXjFRBbTQ99EeB+4E/+3pSROKA3wOXGmOOiIjTb9GpaeuKxWknfD49zlVbf+bDMkIswiM3L6ezp4+y+jbe2VdNTUsXDruVt/ZUIsCdF8/1eZ7I8BDS4yK9SxL0t76ohrue3s7ZcxysvvE0vvDoB8Mm/pHUt3ZhsQixkcP/kVIq0EasoRtj1gJ1J2jyaeBpY8wRd/sqP8WmgliqO6Efrm1jUXos58x18JEFycxyl1A8ZZfShnaSYyJO2NvPc9o4MChRN7R18a1/bGN2UjR//OxpRISFeNuNdemBrUfqOfeet7njiQ/H9HVKTTZ/3BSdC8SLyDsiskVEPjdcQxG5VUQ2i8jm6uqxzxJUwcNmDfX2dlfMTvAen+2+uXqoxpWgy+rbvb354eQ5bByscS1J4HHv6/uoaenkN9ctITLcdWM2z2mjubOHyibf+6f6crC6hc8+uJHmzh7WF9d4d3hSairyR0IPBU4DPgpcAvyniPh8f2yMWW2MKTDGFDgcDj+8tJrO0tyJesXsxAHHwkMsHHT30Msa2ocd+uiR57TR0d1Hab1rXHtfn+GVHRVcfkoqizPiBrSD4evtvnxQUkdbVy8/umoR3b2G9UXaEVFTlz8SeinwmjGm1RhTA6wFTvXDeVWQS4+LIMQiFPS72RliEbITozhY3Upvn6GisYOMERL60izX1z+/zTVKZntZI7WtXVw4f+DtnOMJfejKkMPxTJC6emk69ohQ3t6rCV1NXf5I6M8Bq0QkVESigDOAPX44rwpyVy/N4NZzZg+pj892RHOoppXKpg56+gzpcSdekTE/xc5F852sXnuQpo5u1uytQgTOmTPwXaDDZiUmItTnDdThVDd3YreGYrOGcs4cB2/vqzqp5X+VmkgjJnQReRzYAOSLSKmI3CIit4nIbQDGmD3Aq8B2YBPwoDFm50QGrYLDRxenctel84Ycn5Xkmv3p2Q5vpJILwB0XzaWpo4dfv76fNXsrWZoZR7x7aQIPEWFOst27pvto1LR0kuReFuH8eU6qmjvZWeZ7qYHXd1Vw/5qiUZ9bKX8bcdiiMeaGUbS5B7jHLxGpGe+07Hge+JfhpR3HAEa8KQqwKD2Wa0/L4NH3SgD41jDDHOc4bby6q4Ke3r4RZ8WCq4eeZHP9YbhgnpMQi/DKznJOyYgd0vbJD46yqaSOr14wZ8Dx4qoWnissI9dh46IFydisOp9PTQyd+q+mnNNnJWAReHFbOcCINXSPe65dzO8/s4wL5jm5elmGzzbnz3PS0NbN2/sG1sIP1bTy+KYjQ8opNS2dONw99ITocFbOTuTlHeU+yy5H6tpo7uihrWvgSJjvP7eT/11TzB1PFnL/Gt8bak+Uh9YfYuPB2kl9TRU4mtDVlBMbGcbCtFiaO3tIsoUTEeZ7PZjBRITLT0nl4ZuXD9urv3CeE6fdyt82Hl8A7GhdG9ev3sB3n97B3oqBN0xrWrpIslm9n19+SioltW3sKR/Yrs+9jAG4Ngrx+PBIPe8dqOXbl+QzPzWGXccaR/W9+Mu9r+074X6uB8dwP0FNfZrQ1ZS0Mtc1lHE05ZaxCA2xcN3yTN7ZX01pfRsd3b3c/Mgm2tybXK/Ze3xeXGdPL43t3QMS+iULk7EIvLyjfMB5q1s66exxLTRW0djBzrJGfvLibn784m5iI8O46cwcFqTGDPmDAa79WMsbx7Y2/Gi0dfXQ3t07ZFVLj02H6rjgV/9ie2mD319bBYYmdDUlrXSPTR/NDdGxum55JgL8/JW9/GntQQ5Ut/K7Ty9jcUYsb+2p9LardQ9Z9JRcABJtVk7LjufdAzUDznmk365JFU0dPPJuCQ+uP8TWIw18cdUsbNZQ5qXYqW7upK61y9u2uaObT/zhPa747XqKKps5VNPqc0XIe17by78/PraZqp74fa07D7Db/W7B1x8ZNT1pQldT0vJZCYSHWMhO9L2/6cnIiI/izovzeXF7Ob95cz+XLkzhnLkOLpjn5MOjDdS2uGaS1rj/7d9DB8hOjB5QVgHXEgYeFU0dHKpp4YxZCWy8+0JuPz8PwLsa5N6K46NknvzgKM0dPfQaw6X/s47z732Hu5/ZMeDcHd29PPbeYV7YdowjtaPfbq/W/YejoqmD3r6hNX/P8gqec+pWftOfJnQ1JdmsoTz1lTP58jmzJ+T8/3ZeLpctSiEiLITvfXQ+ABfOS8YYuOe1fTy1pZTqZk9CHzj8MTU2gqrmzgFruR+pa0MEosNDqGzs4FBNK7lOG8kxEVjcS/7Oc2/Vt9ddf+/u7eORd0s4fVYC/7ztTD59ehazHdEDevsAb+2p8i458Ix7U2xjDG/tqaT1BEsR1LW64u/tM1Q1Dy27eGbjHq5rY9exRs7+5du8W1wzpJ2aPjShqynrlIxY4qLCR244DiLC7z69jPV3XUCme5u8hWkx5CRG8cQHR7nzH9t4e5+rnt6/5AKQEhtBb5/xziIFOFLbSlpsJGlxkeytaKa+rdu7Lo2Hw2YlITqcfe4Sx6s7KyhraOfWs2eT57Tx448voiA73vuHxOO5wjKcditnzErg6Q9L6e0z3P3MDm55bDM/emH3sN9j//h87d/q7aHXtfHhkQYAtmk9fVrThK5mLItFSOg3+chiEV77xjmsudO1nP8L7mGTg0suKTGutdz738g8UtdGVkIUKbER3uQ4a1BCFxHmpdi9JZe/bDhMVkIUF8w7vkSBw26lpqWTvj7DfW/u59L71vL2vio+dmoanyzI5HBtG2f89E0e33SUPKeNv285yp5y3xOd+tfqywbdGO3o7vXW1o/UtrLbfY6xTLoaLWMMm0vqdIbtJNCErlQ/1tAQZjtsnJIeS2N7N3Zr6JBhkymxroRe0djB2/uqeHDdweMJPSaCLncpZnBCB1cdfX9lC1sO17GppI7PnJHlLcmAqxff02eob+vi1Z0VVDd3MjfZzqfPyOLyU1L4+JI0zst38qtPnso/b1tJTEQYP39lr8/vpbalk1D3uQf30A/XtmGM611JfVu3d6z6/kr/3yDdcKCWax/YwL/26zo4E00TulI+nDvXtQ7M4HILQGqsa+RNeWMH//tWET95aQ81LV1kJUZ5k32IRbylnP4uXpBCV28f169+n/BQC58ctEeqw+76+uqWTsoa2vnYqWm89LWzyXXYiAoP5b7rl3LvJ0/lE6dlEBcVzk0rs1lbVE1j+9CRMbUtXSTHRBATETokoXuWJz4v3/V9HnAvs1Bc1eLzBmp/24428MtXff8R8Who6+LBdQfp7TPeWv2b/UYQqYmhCV0pH851J7rB5RaA+KgwwkMtHGtoZ29FM7mOaEItwtLMOJLd5ZishCjCfCwtsDI3kQdvKiDUYuHqJekDSj5w/A/IwepWmjt6vFv1DWdFbiLGuDbhGKy2tYskWzhpcZFDEronyZ4793i5Z3lOPJ09fZTWn3i0y2MbSvj9Owe8o4B8+eHzu/jJS3soPNrgLe2s2aMLm000TehK+bA0Mw57RCjOmKEJXURIjY3wrpX+pbNns+tHl3BmXpK3vu6r3OJxfr6TDd+9gB9/fOgWvZ6E7rk5mTbCxKolmXGEWITNJa5NxXr7jHdETG1rJwnR4aTHRQ6poR+qbsVpt7IgLcZ77Kol6QDs91FHf+9ADb9+Yz8AWw67/njsH2b8+oYDtTxb6FqHp6SmlTL3OvXHGjvYd4KSzqGa1hHfHagT04SulA+hIRYeumk53/iI70W+UmIi2FbqmpgzPzUGa6irzu4puQwe4TJYXFQ44aFD//t5Enqh+8bqSAk9KjyUhWkxbC6p54lNR5j7H6+w6Aev8ae1B6lt6SLRZvX20IurXDNSa1o62XiojllJ0disoSRGhxNqcS2bAL7r6L99q4jfvlXElsP13jH3+yqbaXDX+vv7xat7SY+LxCJwuLaVsoZ2ch2u6+GZibu9tIF1/TYLebe4hvPvfYcfvzj8qB01Ml32TalhnD4rYdjnUt2J2yLHJwwBZCZEERUewqmZceN6zejwECLDQthR5vpjkTGKpQ9Oy47n8U1H2FvRzKL0WOpbu3hrbyW1rV0k2sKJiwynsb2bi369lhCLEBcZRmtXD/99tesdQk5SNG1dvSREh5MWG0HRoIRe39rFpkOudwA/eel4wt1f2cwf1x7kD+8cYOPdF5IcE0FPbx+7jjVyy6rZvLTjGCW1bZTVt3NWXhJR4aG8vKOc287J5Y4nCqlu6WTzf1xEXx989+kdWMRVzslMiOKfW0q58yNzuWCekyt/t54bV2Rz3fKscV3TmUR76EqNQ4r7xuhsh23AKJjYyDDev/tCrlicOq7ziggOu5W2rl7CQsRnDX+w5TkJdHT30djezX9/fBEXzHOy5XA9XT19JEaHsyovicUZsXz3snncsmoWKbER/O1LKzjbvQHIj65ayD3XLgZgbop9yMJjb+6ppM+4Vpv88EgD4aEWlmXFsa+i2dvL9gx3PFLXRnevIc9pIycxmqKqFiqbO0iPj+S65ZnsLGvivreKOFjjukfwr33V/HZNEUfq2lh9YwHJ9gh+/OJu9pQ38eL2YxysaWVnWdOAnaKaOrp5akup1uN9GLGHLiIPA1cAVcaYIUU/ETkP165Fh9yHnjbG/MiPMSo15Xh66PNTY4Y8FzNoB6axctitHKlrIzU2csCQxuF4tvD76OJUFqXHcqSuzbsufGK0lVMyYnn+q6uG/fqFacfXdj9jViK/eHUvVU0dON33A17bVUl6XCSfWZHFL1/dx+L0WBakxfD3zUe9C5IVVzWzak6Sd7/WXEc02YlRrC+uwRjXEshXnprGb97Yz2/fKiIuKgyLCA+uP0Th0QauWZrORQuSiY8OZ11RNYVHG7wfMLAM9MzWMn7w/C7yU+wsSh+6Lv1MNpoe+qPApSO0WWeMWeL+0GSugl6KN6HbR2g5dg53r3ykES4ezpgIHrl5OT+5ytXfKsg5vkdrgm1sM209wzU9Y8bbu3pZV1TNRxYk81F3jb0gJ4G5yXY6uvvwdJI92/p5hj/munvonucz4iKJCAvhcytzAPhUQSaXLUrxlnLuvCQfcJWP7rhoLitnJ1JS28aava6hjiW1rXR093ofw/Gbs4MdrWvjwCiXBX5rT+WACVjT3YgJ3RizFqibhFiUmjbmOG1YBE7PGb7OPl6eG6Mj3RDt7/x5Tu+We057BDmJrjHwSdEjl2z6m59qx2G3ehP6ByV1dPb0cf48J9mJ0Txy83JuPWe2976BPSKUxRmx3p55cVULyTFWYiLCyOm3sJpn1cybz8rhhtMz+eKqWd5RNZ8/K2fIMsmejb9f21VJWIjQZ46XdTyLiPkaqtnR3cv1q9/nkt+s5X/eLDphWaautYtbHtvMPa+deEz9eHR093LjQxvZcnhyU6e/augrRWSbiLwiIgv9dE6lpqzZDhsf/ufFFExgQh/NDdHheOJKHGMPXUQ4d66DdUU19PT2seFgLaEWYbm713/+PCcJ0eHMdboS+pm5ieQn2ymuck9Mqm4h12EDICcpyn3O45OxYiPD+Nk1i3HGRLA8J55HP7+cb1w0dCTRKemxhFiE3j7DRxYkA8dXqfSMsvHVQ3/svRLKGtopyInnN2/uZ/0JFhvzrKnzwrZy2t3r4fvLnvIm1hXV8Nh7h0du7Ef+SOhbgWxjzKnA/wLPDtdQRG4Vkc0isrm6WqcBq+ktNurkauXDGU8PfbBrlqazcnaiz5muIzkv30FjezcfHm3gvQO1LM2KIyp84O222KgwvnZBHl9yLyxW09JJQ1sXB6tayHO6EnpGfBQi4LRbfQ7RFBHOy3f63JEqMjyEee53AVctSccaamFfRTPGuHaGigoPobS+naom1/h6YwwbDtRy/9vFXDDPyW+uWwIwZOXK/va5/0C0dPbw6q5yGtu7eWj9Ie78+zbe2F05YDXNsfLcWF6zt4rOHv/+sTiRk07oxpgmY0yL+/HLQJiIJA3TdrUxpsAYU+BwOE72pZUKSk4/JPQz85J4/NYVPmerjuScuQ7sEaH86vV97Cht8G42Mtg3L86nICfBm8A3HKilubPH20OPCAshLTZy3LtOLc2KA1x19TnJNvZVNlPV7NoZ6tJFKcDxssvXnijkhj+9T3iIhbsvn0+SzYoIVDYNP5t1X2UzcVFhZCVE8fNX9rLip2/x4xd389quCr705818/cnCcY+k8SyY1tLZw3vFA/d0/enLe7z3BvztpBO6iKSIiLgfn+4+p+5Kq9Q4rZqTxPcun+/dhm+yxUSE8W/n5fH+wTr6DKzM9dk/8/Ik9Kfda7V7Pge4ZdUsPn1G9rji+PI5ufzqk6eSZLOSnxzDvopmb4/7skWphIdaeP9gHXsrmnhh2zFuPjOHd79zAXlOG2EhFhKjw6n2sQ68x76KZvKT7XxuZTb1bd1csTiVF/99FR9+/yN87cI5vLS9nL8Nsx9rX5/hzr9v806EMsbw+q4KvvyXzRyobmFvRROnZsRit4YOmHjV2NbN6rUH2X3M9wqZJ2s0wxYfB84DkkSkFPgBEOb+Jh4ArgW+IiI9QDtwvdEBokqNmzU0hC9N0MYeo/X5s3L484YSalu7vD3l4WTER2ENtfDG7krCQy3eUgnAF1bNGncMmQlR3gXOFqTF8NTWUu8GHHlOGx9ZkMzfNh2huKqFiDALd1w0Z0D5xmGPoGqYHroxhv2VLVyzLJ1bVs3i5jNzCO33buaOC+fw4ZF6fvTCbi5ZmDJkPsAvXtvLU1tLcdit/OcVC/j5K3v549qDgGv9n73lzXx8aTo5SdG8saeSnxuDiPDhUdc7imVZ8UyEERO6MeaGEZ6/H7jfbxEppQIuIiyE396wlCO1bT5r3P2FWIR7PnkqzR3dXDQ/mcRRTIYaq0sWJvPjF3fz8PpDWMS1efgPP7aQ94prWF9cw2fOyBqyGYrTbqWqeWhCL6lpxeAqh+Sn2BERQkMGjve3WIRvX5LPlfe/y/qiGj6+NN373B//dYA//usgabERHGvsoKalk9d3V7IqL4nYyDD+uaWUzp4+5qfGYBF4rtA1QSrXYWPr4XoswrhnEo9EZ4oqpXxanpPAJ07LGFXbK09N4zNnZHtXm/S3jPgoVs5OpKmjh9TYSMJDLTjsVn52zWLS4yK5xcc7geQYK5VNA0suR2rbuPDX/+KzD24EGPBuYrCFabHERYWxruj4SJk/vHOAn72ylysWp/LzT7hm1248WMehmlZWzE7gE6eleydbzU+1s8w96Wure0TO1iMNzEuJIdo6MauuaEJXSk0Lnj8uWf3Wmb90UQrr7zqf2Q7bkPZOewQ1LZ0DVnB8fXcFvX3Gu6Tv3OThE3qIRTgrN4n1xdXePVx/8epePnZqGvddt4RT3LNUn9x8FIDFGXGcPcdBQnQ44l7jJ89hwx4RytYjDfT2GQqPNrAsO+6kr8VwNKErpaaFyxalYLOGkuscurWfL84YK33GtYywx5t7KpmXYucnH1/EtadlYB9hmYZVc5KobOrk5R0V3PFkIQvTYrjn2sWEhliIjw4nNTbCu57N4oxYwkIsfG5lNqvci5FZLMKSzDg+PFLP/spmWjp7OC17YurnoKstKqWmiWhrKM/efiaJo5z96nTv/lTV1InTHkFDWxcflNTzlXNz+eyKbD67YuTRN6vyXCN8bv/bVhx2Kw989rQB9xTmp8ZQ3thBdmKUt4Z/x6CJUsuy4vntmiJe2VHu/XyiaA9dKTVt5Dnt3iUORuLZnKTKPXTx7X1V9PYZLnLPPB2NzIQoFqXHkJ9s59nbzxqyraBnLZ/FGXHDnmNZdjzGwG/XFHP6rIQBJSN/0x66UiooeSZoeYYuPld4DKfdyuIxrtD4jy+fiTXU4nPlS89qm6dmDH/OJZlxRIRZOCU9lodvXj5sicgfNKErpYKSZ9mDyqZOiquaeWdfNd+4aO6oliTuLzJ8+GGbK2cnUpAdz0Xzh+/1x0aG8dad5+Gw+V4CwZ80oSulgpI1NIT4qDCqmjt4aH0J4aEWPrvCv7seJdqs/PMrZ47YbrzLH4yVJnSlVNBy2iPYdKiOI3VtfGJZ+oRMeppK9KaoUipoOWOsFFW1kBEfye3n5wU6nAmnPXSlVNC69ZzZnJmbxOfPyhlxCYNgoAldKRW0zp7j8G6GPRNoyUUppYKEJnSllAoSmtCVUipIaEJXSqkgMWJCF5GHRaRKRHaO0G65iPSIyLX+C08ppdRojaaH/ihw6YkaiEgI8AvgdT/EpJRSahxGTOjGmLVA3QjN/h14CqjyR1BKKaXG7qRr6CKSDlwN/GEUbW8Vkc0isrm6uvpkX1oppVQ//phYdB9wlzGmb6RlIY0xq4HVACJSLSKHx/F6SUDNiK0mn8Y1dlM1No1rbKZqXDB1YzuZuIbdmcMfCb0AeMKdzJOAy0Wkxxjz7Im+yBgzrulbIrLZGFMwnq+dSBrX2E3V2DSusZmqccHUjW2i4jrphG6M8W63LSKPAi+OlMyVUkr534gJXUQeB84DkkSkFPgBEAZgjHlgQqNTSik1aiMmdGPMDaM9mTHm5pOKZnRWT8JrjIfGNXZTNTaNa2ymalwwdWObkLjEGDMR51VKKTXJdOq/UkoFCU3oSikVJKZNQheRS0Vkn4gUi8h3AhxLpoi8LSK7RWSXiHzdffyHIlImIoXuj8sDEFuJiOxwv/5m97EEEXlDRIrc/8ZPckz5/a5JoYg0icgdgbpevtYnGu4aictv3b9320Vk2STHdY+I7HW/9jMiEuc+niMi7f2u3YQNUBgmrmF/diLyXff12icil0xyXE/2i6lERArdxyfzeg2XHyb+d8wYM+U/gBDgADAbCAe2AQsCGE8qsMz92A7sBxYAPwS+FeBrVQIkDTr2S+A77sffAX4R4J9lBa7JEQG5XsA5wDJg50jXCLgceAUQYAWwcZLjuhgIdT/+Rb+4cvq3C8D18vmzc/8/2AZYgVnu/7chkxXXoOd/BXw/ANdruPww4b9j06WHfjpQbIw5aIzpAp4ArgpUMMaYcmPMVvfjZmAPkB6oeEbhKuAx9+PHgI8HLhQuBA4YY8YzS9gvjO/1iYa7RlcBfzYu7wNxIpI6WXEZY143xvS4P30fyJiI1x5rXCdwFfCEMabTGHMIKMb1/3dS4xLXTMdPAY9PxGufyAnyw4T/jk2XhJ4OHO33eSlTJIGKSA6wFNjoPvRV99umhye7tOFmgNdFZIuI3Oo+lmyMKXc/rgCSAxCXx/UM/E8W6OvlMdw1mkq/e1/A1ZPzmCUiH4rIv0Tk7ADE4+tnN1Wu19lApTGmqN+xSb9eg/LDhP+OTZeEPiWJiA3XKpN3GGOacC1QlgssAcpxveWbbKuMMcuAy4DbReSc/k8a13u8gIxVFZFw4ErgH+5DU+F6DRHIazQcEfke0AP81X2oHMgyxiwFvgn8TURiJjGkKfmz6+cGBnYcJv16+cgPXhP1OzZdEnoZkNnv8wz3sYARkTBcP6y/GmOeBjDGVBpjeo0xfcCfmKC3midijClz/1sFPOOOodLzFs79b6CWOb4M2GqMqXTHGPDr1c9w1yjgv3sicjNwBfAZdyLAXdKodT/egqtWPXeyYjrBz24qXK9Q4BrgSc+xyb5evvIDk/A7Nl0S+gfAHBGZ5e7lXQ88H6hg3PW5h4A9xphf9zvev+51NXDCXZ4mIK5oEbF7HuO6obYT17W6yd3sJuC5yYyrnwG9pkBfr0GGu0bPA59zj0RYATT2e9s84UTkUuD/AVcaY9r6HXeIa2MZRGQ2MAc4OIlxDfezex64XkSsIjLLHdemyYrL7SJgrzGm1HNgMq/XcPmByfgdm4y7vv74wHUneD+uv6zfC3Asq3C9XdoOFLo/Lgf+AuxwH38eSJ3kuGbjGmGwDdjluU5AIvAWUAS8CSQE4JpFA7VAbL9jAbleuP6olAPduOqVtwx3jXCNPPid+/duB1AwyXEV46qven7PHnC3/YT7Z1wIbAU+NslxDfuzA77nvl77gMsmMy738UeB2wa1nczrNVx+mPDfMZ36r5RSQWK6lFyUUkqNQBO6UkoFCU3oSikVJDShK6VUkNCErpRSQUITulJKBQlN6EopFST+P+XLKJaxjTmdAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [p for p in range(1,len(loss_list)+1)]\n",
    "y = loss_list\n",
    "plt.plot(x,y)\n",
    "plt.title('Train loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [p for p in range(1,len(loss_list)+1)]\n",
    "y1 = acc_list\n",
    "y2 = test_acc_list\n",
    "plt.ylim(0,1)\n",
    "'''\n",
    "#20\n",
    "plt.plot(x,train_acc_lists[0],label = '20 Train acc', color = \"crimson\")\n",
    "plt.plot(x,test_acc_lists[0],label = '20 Test acc', color = \"crimson\",linestyle = 'dashed')\n",
    "\n",
    "#30\n",
    "plt.plot(x,train_acc_lists[1],label = '30 Train acc', color = \"darkblue\")\n",
    "plt.plot(x,test_acc_lists[1],label = '30 Test acc', color = \"darkblue\",linestyle = 'dashed')\n",
    "\n",
    "#40\n",
    "plt.plot(x,train_acc_lists[2],label = '40 Train acc', color = \"green\")\n",
    "plt.plot(x,test_acc_lists[2],label = '40 Test acc', color = \"green\",linestyle = 'dashed')\n",
    "'''\n",
    "plt.plot(x,y1,label='train acc')\n",
    "plt.plot(x,y2,label='test acc')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('Training and Test accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4065, 0.4174, 0.4706, 0.412, 0.4171, 0.41573333333333334, 0.41586666666666666, 0.4169333333333333, 0.4116666666666667, 0.41386666666666666, 0.4119, 0.4167, 0.4145, 0.4161666666666667, 0.4157666666666667, 0.4141]\n",
      "[0.3377, 0.3246, 0.2941, 0.3054, 0.2995, 0.298, 0.3004, 0.3012, 0.2941, 0.2941, 0.3006, 0.2993, 0.3011, 0.2949, 0.3034, 0.2941]\n"
     ]
    }
   ],
   "source": [
    "print(save_train_acc)\n",
    "print(save_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x*x-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_x_value = 5\n",
    "ini_x_tensor = ini_x_value*torch.ones(1, 1, dtype = torch.float64)\n",
    "x = Variable(ini_x_tensor, requires_grad=True)\n",
    "print(f'roop {0:<4d} x = {x.item()}')\n",
    "\n",
    "roop = 0\n",
    "while roop < 10:\n",
    "    roop += 1\n",
    "    # 勾配の計算\n",
    "    f(x).backward()\n",
    "    # xの更新\n",
    "    x.data -= (f(x)/x.grad).data\n",
    "    # 勾配を0に設定\n",
    "    x.grad.zero_()\n",
    "    print(f'roop {roop:<4d} x = {x.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 必要なもの\n",
    "lossの履歴  \n",
    "trainのacc  \n",
    "testのacc  \n",
    "実行時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_logs = []\n",
    "train_acc_logs = []\n",
    "test_acc_logs = []\n",
    "run_time_logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8-16-32-64-128-128-64-32-16-10\n",
    "#8-64-512-512-64-10\n",
    "#8-96-1152-1152-500-150-20-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ネットワーク設定\n",
    "class GCN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN1,self).__init__()\n",
    "        self.conv1 = GraphConv(8,64)\n",
    "        self.conv2 = GraphConv(64,512)\n",
    "    \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.liner1 = torch.nn.Linear(512,64)\n",
    "        self.liner2 = torch.nn.Linear(64,10)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(p = 0.2)\n",
    "\n",
    "    def forward(self,g,n_feat,e_feat = None):\n",
    "        h = F.relu(self.conv1(g,n_feat,None,e_feat))\n",
    "        h = self.dropout(h)\n",
    "        h = self.conv2(g,h,None,e_feat)\n",
    "        \n",
    "        h = self.flatten(h)\n",
    "\n",
    "        h = F.relu(self.liner1(h))\n",
    "        h = self.dropout(h)\n",
    "        h = self.liner2(h)\n",
    "        \n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        return dgl.mean_nodes(g,'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ネットワーク設定\n",
    "class GCN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN2,self).__init__()\n",
    "        self.conv1 = GraphConv(8,96)\n",
    "        self.conv2 = GraphConv(96,1152)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.liner1 = torch.nn.Linear(1152,500)\n",
    "        self.liner2 = torch.nn.Linear(500,150)\n",
    "        self.liner3 = torch.nn.Linear(150,20)\n",
    "        self.liner4 = torch.nn.Linear(20,10)\n",
    "        self.dropout = torch.nn.Dropout(p = 0.2)\n",
    "\n",
    "    def forward(self,g,n_feat,e_feat = None):\n",
    "        h = F.relu(self.conv1(g,n_feat,None,e_feat))\n",
    "        h = self.dropout(h)\n",
    "        h = self.conv2(g,h,None,e_feat)\n",
    "        \n",
    "        h = self.flatten(h)\n",
    "\n",
    "        h = F.relu(self.liner1(h))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.liner2(h))\n",
    "        h = self.dropout(h)\n",
    "        h = self.liner3(h)\n",
    "        \n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        return dgl.mean_nodes(g,'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_list = []\n",
    "opt_list = []\n",
    "model1 = GCN1()\n",
    "model_list.append(model1)\n",
    "model2 = GCN2()\n",
    "model_list.append(model2)\n",
    "model1.to(device)\n",
    "model2.to(device)\n",
    "optimizer1 = optim.Adam(model1.parameters(),lr = 0.01)\n",
    "opt_list.append(optimizer1)\n",
    "optimizer2 = optim.Adam(model2.parameters(),lr = 0.01)\n",
    "opt_list.append(optimizer2)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model_list)):\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "\n",
    "    num_correct = 0\n",
    "    num_tests = 0\n",
    "    start = time.time()\n",
    "    runmodel = model_list[i]\n",
    "    opt = opt_list[i]\n",
    "    runmodel.train()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for batched_graph,labels in traindataloader:\n",
    "            batched_graph = batched_graph.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred = runmodel(batched_graph, batched_graph.ndata['feat value'].float(),batched_graph.edata['distance'].float())\n",
    "            loss = F.cross_entropy(pred,labels)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "            num_tests += len(labels)\n",
    "        loss_list.append(loss.item())\n",
    "        acc_list.append(num_correct / num_tests)\n",
    "    loss_logs.append(loss_list)\n",
    "    run_time_logs.append(time.time() - start)\n",
    "\n",
    "    num_correct = 0\n",
    "    num_tests = 0\n",
    "    runmodel.eval()\n",
    "    for batched_graph,labels in traindataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = runmodel(batched_graph, batched_graph.ndata['feat value'].float(),batched_graph.edata['distance'].float())\n",
    "        num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "        num_tests += len(labels)\n",
    "    train_acc_logs.append(num_correct / num_tests)\n",
    "\n",
    "    num_correct = 0\n",
    "    num_tests = 0\n",
    "    for batched_graph,labels in testdataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = runmodel(batched_graph, batched_graph.ndata['feat value'].float(),batched_graph.edata['distance'].float())\n",
    "        num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "        num_tests += len(labels)\n",
    "    test_acc_logs.append(num_correct / num_tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss_logs)\n",
    "print(train_acc_logs)\n",
    "print(test_acc_logs)\n",
    "print(run_time_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlog = model_list[0].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlog.__sizeof__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.01)\n",
    "#optimizer = optim.SGD(params=model.parameters(),lr=0.001,momentum=0.9)\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.01)\n",
    "#optimizer = optim.SGD(params=model.parameters(),lr=0.001,momentum=0.9)\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4,5,6])\n",
    "x_label = ['5','10','20','30','40','50']\n",
    "normal_Train_acc = [0.4089,0.3904,0.4532,0.4585,0.459,0.]\n",
    "normal_Test_acc = [0.2325,0.281,0.285,0.3005,0.302,0.]\n",
    "incpos_Train_acc = [0.4575,0.48,0.4853,0.4418,0.4774,0.]\n",
    "incpos_Test_acc = [0.2375,0.294,0.3035,0.34,0.3345,0.]\n",
    "std_Train_acc = [0.5268,0.5211,0.5501,0.5672,0.5776,0.5802]\n",
    "std_Test_acc = [0.2125,0.244,0.313,0.3255,0.364,0.3715]\n",
    "Train_data = [normal_Train_acc,incpos_Train_acc,std_Train_acc]\n",
    "Test_data = [normal_Test_acc,incpos_Test_acc,std_Test_acc]\n",
    "margin = 0.2\n",
    "totoal_width = 1 - margin\n",
    "\n",
    "for i,h in enumerate(Train_data):\n",
    "    pos = x - totoal_width *( 1- (2*i+1)/len(Train_data) )/2\n",
    "    plt.bar(pos, h, width = totoal_width/len(Train_data))\n",
    "plt.xticks(x,x_label)\n",
    "plt.title('Training acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,h in enumerate(Train_data):\n",
    "    pos = x - totoal_width *( 1- (2*i+1)/len(Test_data) )/2\n",
    "    plt.bar(pos, h, width = totoal_width/len(Test_data))\n",
    "plt.xticks(x,x_label)\n",
    "plt.title('Test acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchmodel = GCN()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torchmodel.to(device)\n",
    "optimizer = optim.Adam(torchmodel.parameters(),lr = 0.001)\n",
    "epochs = 15\n",
    "\n",
    "history = {'train_loss':[],'train_acc':[],'test_acc':[]}\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for e in range(epochs):\n",
    "    torchmodel.train()\n",
    "    loss = None\n",
    "\n",
    "    for i,(batched_graph, labels) in enumerate(traindataloader):\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = torchmodel(batched_graph, batched_graph.ndata['feat value'].float())\n",
    "        loss = F.cross_entropy(pred,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #if (i+1) % 10 == 0:\n",
    "        #    print(f'Training log: {e+1} epoch ({(i+1)*200} / 10000 train. data). Loss: {loss.item()}')\n",
    "\n",
    "    history['train_loss'].append(loss.item())\n",
    "\n",
    "    torchmodel.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i,(batched_graph, labels) in enumerate(tqdm(traindataloader)):\n",
    "            batched_graph = batched_graph.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred = torchmodel(batched_graph, batched_graph.ndata['feat value'].float())\n",
    "            correct += (pred.argmax(1) == labels).sum().item()\n",
    "            num_tests += len(labels)\n",
    "\n",
    "    acc = float(correct/num_tests)\n",
    "    history['train_acc'].append(acc)\n",
    "\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i,(batched_graph, labels) in enumerate(tqdm(testdataloader)):\n",
    "            batched_graph = batched_graph.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred = torchmodel(batched_graph, batched_graph.ndata['feat value'].float())\n",
    "            correct += (pred.argmax(1) == labels).sum().item()\n",
    "            num_tests += len(labels)\n",
    "\n",
    "    acc = float(correct/num_tests)\n",
    "    history['test_acc'].append(acc)\n",
    "\n",
    "max_train_acc = max(history['train_acc'])\n",
    "min_train_loss = min(history['train_loss'])\n",
    "max_test_acc = max(history['test_acc'])\n",
    "\n",
    "print(f'Max train accuracy: {max_train_acc}')\n",
    "print(f'Min train loss: {min_train_loss}')\n",
    "print(f'Max test acc: {max_test_acc}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9512f24219e729098bc0f30caa9285407db90c80b780d5e3a7fd78ad6fa2427c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('GDW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
