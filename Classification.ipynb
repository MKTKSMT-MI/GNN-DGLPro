{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.data\n",
    "from dgl.nn import GraphConv\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#トレーニング用データセットクラス\n",
    "class CIFAR10TrainDataset(DGLDataset):\n",
    "    def __init__(self,data_path):\n",
    "        self.data_path = data_path\n",
    "        super().__init__(name='cifar10_train__gprah')\n",
    "    \n",
    "    def process(self):\n",
    "        GRAPHS, LABELS = dgl.load_graphs(self.data_path) #保存したグラーフデータの読み込み\n",
    "        self.graphs = GRAPHS #グラフリストを代入\n",
    "        self.labels = LABELS['label'] #ラベル辞書の値のみ代入\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "\n",
    "class CIFAR10TestDataset(DGLDataset):\n",
    "    def __init__(self,data_path):\n",
    "        self.data_path = data_path\n",
    "        super().__init__(name='cifar10_test_gprah')\n",
    "    \n",
    "    def process(self):\n",
    "        GRAPHS, LABELS = dgl.load_graphs(self.data_path) #保存したグラーフデータの読み込み\n",
    "        self.graphs = GRAPHS #グラフリストを代入\n",
    "        self.labels = LABELS['label'] #ラベル辞書の値のみ代入\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/MyDataset/train_graphs_six_f_in_pos_50_std.dgl\"\n",
    "traindataset = CIFAR10TrainDataset(\"./data/MyDataset/train_graphs_six_f_in_pos_40_std.dgl\")\n",
    "testdataset = CIFAR10TestDataset(\"./data/MyDataset/test_graphs_six_f_in_pos_40_std.dgl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_wokers = 0\n",
      "posix\n"
     ]
    }
   ],
   "source": [
    "if os.name =='posix':\n",
    "    num_workers = 2\n",
    "else:\n",
    "    num_workers = 0\n",
    "num_workers = 0\n",
    "traindataloader = GraphDataLoader(traindataset,batch_size = 2500,shuffle = True,num_workers = num_workers,pin_memory = True)\n",
    "testdataloader = GraphDataLoader(testdataset,batch_size = 5000,shuffle = True,num_workers = num_workers,pin_memory = True)\n",
    "print(f'num_wokers = {num_workers}')\n",
    "print(os.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traindataset[0][0].ndata['feat value'].shape)\n",
    "for i in range(10,20):\n",
    "    print(traindataset[3][0].ndata['feat value'][i])\n",
    "print(traindataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traindataset)\n",
    "print(traindataset[0][0].ndata['feat value'].shape)\n",
    "for i in range(10,20):\n",
    "    print(traindataset[3][0].ndata['feat value'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ネットワーク設定\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN,self).__init__()\n",
    "        self.conv1 = GraphConv(8,16)\n",
    "        self.conv2 = GraphConv(16,32)\n",
    "        self.conv3 = GraphConv(32,128)\n",
    "        self.conv4 = GraphConv(64,128)\n",
    "        self.dropout =nn.Dropout(0.4)\n",
    "        self.meanpooling = nn.AvgPool1d(2)\n",
    "        self.maxpooling = nn.MaxPool1d(2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64,128)\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        self.fc3 = nn.Linear(64,32)\n",
    "        self.fc4 = nn.Linear(32,10)\n",
    "\n",
    "\n",
    "    def forward(self,g,n_feat,e_feat = None):\n",
    "        h = F.relu(self.conv1(g,n_feat,None,e_feat))\n",
    "        h = F.relu(self.conv2(g,h,None,e_feat))\n",
    "        h = self.dropout(h)\n",
    "        h = self.conv3(g,h,None,e_feat)\n",
    "\n",
    "        #h = self.meanpooling(h)\n",
    "        h = self.maxpooling(h)\n",
    "\n",
    "        h = self.flatten(h)\n",
    "\n",
    "        h = F.relu(self.fc1(h))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.fc2(h))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.fc3(h))\n",
    "        h = self.fc4(h)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        return dgl.mean_nodes(g,'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 32 64 128 x4 '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.02)\n",
    "#optimizer = optim.SGD(params=model.parameters(),lr=0.03,momentum=0.9)\n",
    "epochs = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_train_acc = []\n",
    "save_test_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = GraphConv(8,16)\n",
    "conv2 = GraphConv(16,32)\n",
    "conv3 = GraphConv(32,10)\n",
    "conv4 = GraphConv(64,128)\n",
    "dropout =nn.Dropout(0.2)\n",
    "meanpooling = nn.AvgPool1d(32)\n",
    "flatten = nn.Flatten()\n",
    "fc1 = nn.Linear(1,60)\n",
    "fc2 = nn.Linear(60,10)\n",
    "for i,p in traindataloader:\n",
    "    h = i.ndata['feat value'].float()\n",
    "    print(i.ndata['feat value'].float().shape)\n",
    "    h = conv1(i,h)\n",
    "    print(f'conv1:{h.shape}')\n",
    "    h = conv2(i,h)\n",
    "    print(f'conv2:{h.shape}')\n",
    "    h = meanpooling(h)\n",
    "    print(f'meanpooling:{h.shape}')\n",
    "    h = flatten(h)\n",
    "    print(f'flatten:{h.shape}')\n",
    "    h = fc1(h)\n",
    "    print(f'fc1:{h.shape}')\n",
    "    h = fc2(h)\n",
    "    print(f'fc2:{h.shape}')\n",
    "    i.ndata['h'] = h\n",
    "    q = dgl.mean_nodes(i,'h')\n",
    "    break\n",
    "loss = F.cross_entropy(q,p)\n",
    "print(loss)\n",
    "print(loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [11:25<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.527\n",
      "Test accuracy: 0.3201\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "test_num_correct = 0\n",
    "test_num_tests = 0\n",
    "#,batched_graph.edata['distance'].float()\n",
    "BP = 0\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    if BP != 0:\n",
    "        break\n",
    "    model.train()\n",
    "    for batched_graph, labels in traindataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat value'].float(),batched_graph.edata['distance'].float())\n",
    "        loss = F.cross_entropy(pred,labels)\n",
    "        if loss.item() < 0.05:\n",
    "            BP = 0\n",
    "            break\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "        num_tests += len(labels)\n",
    "    loss_list.append(loss.item())\n",
    "    acc_list.append(num_correct / num_tests)\n",
    "    \n",
    "    model.eval()\n",
    "    for tbatched_graph, tlabels in testdataloader:\n",
    "        tbatched_graph = tbatched_graph.to(device)\n",
    "        tlabels = tlabels.to(device)\n",
    "        tpred = model(tbatched_graph, tbatched_graph.ndata['feat value'],tbatched_graph.edata['distance'].float())\n",
    "        test_num_correct += (tpred.argmax(1) == tlabels).sum().item()\n",
    "        test_num_tests += len(tlabels)\n",
    "\n",
    "    Tacc = test_num_correct / test_num_tests\n",
    "    #print('Training accuracy:', Tacc)\n",
    "    #test_acc_list.append(Tacc)\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    model.train()\n",
    "    for batched_graph, labels in traindataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat value'],batched_graph.edata['distance'].float())\n",
    "        num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "        num_tests += len(labels)\n",
    "\n",
    "    print('Training accuracy:', num_correct / num_tests)\n",
    "    save_train_acc.append(num_correct / num_tests)\n",
    "\n",
    "    num_correct = 0\n",
    "    num_tests = 0\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    for batched_graph, labels in testdataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat value'].float(),batched_graph.edata['distance'].float())\n",
    "        num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "        num_tests += len(labels)\n",
    "\n",
    "    print('Test accuracy:', num_correct / num_tests)\n",
    "    save_test_acc.append(num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#5:40\n",
    "#3:15\n",
    "print(torch.cuda.device_count())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [p for p in range(1,len(loss_list)+1)]\n",
    "y = loss_list\n",
    "plt.plot(x,y)\n",
    "plt.title('Train loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [p for p in range(1,len(loss_list)+1)]\n",
    "y1 = acc_list\n",
    "y2 = test_acc_list\n",
    "plt.ylim(0,1)\n",
    "'''\n",
    "#20\n",
    "plt.plot(x,train_acc_lists[0],label = '20 Train acc', color = \"crimson\")\n",
    "plt.plot(x,test_acc_lists[0],label = '20 Test acc', color = \"crimson\",linestyle = 'dashed')\n",
    "\n",
    "#30\n",
    "plt.plot(x,train_acc_lists[1],label = '30 Train acc', color = \"darkblue\")\n",
    "plt.plot(x,test_acc_lists[1],label = '30 Test acc', color = \"darkblue\",linestyle = 'dashed')\n",
    "\n",
    "#40\n",
    "plt.plot(x,train_acc_lists[2],label = '40 Train acc', color = \"green\")\n",
    "plt.plot(x,test_acc_lists[2],label = '40 Test acc', color = \"green\",linestyle = 'dashed')\n",
    "'''\n",
    "plt.plot(x,y1,label='train acc')\n",
    "plt.plot(x,y2,label='test acc')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('Training and Test accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(save_train_acc)\n",
    "print(save_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x*x-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_x_value = 5\n",
    "ini_x_tensor = ini_x_value*torch.ones(1, 1, dtype = torch.float64)\n",
    "x = Variable(ini_x_tensor, requires_grad=True)\n",
    "print(f'roop {0:<4d} x = {x.item()}')\n",
    "\n",
    "roop = 0\n",
    "while roop < 10:\n",
    "    roop += 1\n",
    "    # 勾配の計算\n",
    "    f(x).backward()\n",
    "    # xの更新\n",
    "    x.data -= (f(x)/x.grad).data\n",
    "    # 勾配を0に設定\n",
    "    x.grad.zero_()\n",
    "    print(f'roop {roop:<4d} x = {x.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 必要なもの\n",
    "lossの履歴  \n",
    "trainのacc  \n",
    "testのacc  \n",
    "実行時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_logs = []\n",
    "train_acc_logs = []\n",
    "test_acc_logs = []\n",
    "run_time_logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8-16-32-64-128-128-64-32-16-10\n",
    "#8-64-512-512-64-10\n",
    "#8-96-1152-1152-500-150-20-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ネットワーク設定\n",
    "class GCN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN1,self).__init__()\n",
    "        self.conv1 = GraphConv(8,64)\n",
    "        self.conv2 = GraphConv(64,512)\n",
    "    \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.liner1 = torch.nn.Linear(512,64)\n",
    "        self.liner2 = torch.nn.Linear(64,10)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(p = 0.2)\n",
    "\n",
    "    def forward(self,g,n_feat,e_feat = None):\n",
    "        h = F.relu(self.conv1(g,n_feat,None,e_feat))\n",
    "        h = self.dropout(h)\n",
    "        h = self.conv2(g,h,None,e_feat)\n",
    "        \n",
    "        h = self.flatten(h)\n",
    "\n",
    "        h = F.relu(self.liner1(h))\n",
    "        h = self.dropout(h)\n",
    "        h = self.liner2(h)\n",
    "        \n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        return dgl.mean_nodes(g,'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ネットワーク設定\n",
    "class GCN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN2,self).__init__()\n",
    "        self.conv1 = GraphConv(8,96)\n",
    "        self.conv2 = GraphConv(96,1152)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.liner1 = torch.nn.Linear(1152,500)\n",
    "        self.liner2 = torch.nn.Linear(500,150)\n",
    "        self.liner3 = torch.nn.Linear(150,20)\n",
    "        self.liner4 = torch.nn.Linear(20,10)\n",
    "        self.dropout = torch.nn.Dropout(p = 0.2)\n",
    "\n",
    "    def forward(self,g,n_feat,e_feat = None):\n",
    "        h = F.relu(self.conv1(g,n_feat,None,e_feat))\n",
    "        h = self.dropout(h)\n",
    "        h = self.conv2(g,h,None,e_feat)\n",
    "        \n",
    "        h = self.flatten(h)\n",
    "\n",
    "        h = F.relu(self.liner1(h))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.liner2(h))\n",
    "        h = self.dropout(h)\n",
    "        h = self.liner3(h)\n",
    "        \n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        return dgl.mean_nodes(g,'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_list = []\n",
    "opt_list = []\n",
    "model1 = GCN1()\n",
    "model_list.append(model1)\n",
    "model2 = GCN2()\n",
    "model_list.append(model2)\n",
    "model1.to(device)\n",
    "model2.to(device)\n",
    "optimizer1 = optim.Adam(model1.parameters(),lr = 0.01)\n",
    "opt_list.append(optimizer1)\n",
    "optimizer2 = optim.Adam(model2.parameters(),lr = 0.01)\n",
    "opt_list.append(optimizer2)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model_list)):\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "\n",
    "    num_correct = 0\n",
    "    num_tests = 0\n",
    "    start = time.time()\n",
    "    runmodel = model_list[i]\n",
    "    opt = opt_list[i]\n",
    "    runmodel.train()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for batched_graph,labels in traindataloader:\n",
    "            batched_graph = batched_graph.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred = runmodel(batched_graph, batched_graph.ndata['feat value'].float(),batched_graph.edata['distance'].float())\n",
    "            loss = F.cross_entropy(pred,labels)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "            num_tests += len(labels)\n",
    "        loss_list.append(loss.item())\n",
    "        acc_list.append(num_correct / num_tests)\n",
    "    loss_logs.append(loss_list)\n",
    "    run_time_logs.append(time.time() - start)\n",
    "\n",
    "    num_correct = 0\n",
    "    num_tests = 0\n",
    "    runmodel.eval()\n",
    "    for batched_graph,labels in traindataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = runmodel(batched_graph, batched_graph.ndata['feat value'].float(),batched_graph.edata['distance'].float())\n",
    "        num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "        num_tests += len(labels)\n",
    "    train_acc_logs.append(num_correct / num_tests)\n",
    "\n",
    "    num_correct = 0\n",
    "    num_tests = 0\n",
    "    for batched_graph,labels in testdataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = runmodel(batched_graph, batched_graph.ndata['feat value'].float(),batched_graph.edata['distance'].float())\n",
    "        num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "        num_tests += len(labels)\n",
    "    test_acc_logs.append(num_correct / num_tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss_logs)\n",
    "print(train_acc_logs)\n",
    "print(test_acc_logs)\n",
    "print(run_time_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlog = model_list[0].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlog.__sizeof__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.01)\n",
    "#optimizer = optim.SGD(params=model.parameters(),lr=0.001,momentum=0.9)\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.01)\n",
    "#optimizer = optim.SGD(params=model.parameters(),lr=0.001,momentum=0.9)\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4,5,6])\n",
    "x_label = ['5','10','20','30','40','50']\n",
    "normal_Train_acc = [0.4089,0.3904,0.4532,0.4585,0.459,0.]\n",
    "normal_Test_acc = [0.2325,0.281,0.285,0.3005,0.302,0.]\n",
    "incpos_Train_acc = [0.4575,0.48,0.4853,0.4418,0.4774,0.]\n",
    "incpos_Test_acc = [0.2375,0.294,0.3035,0.34,0.3345,0.]\n",
    "std_Train_acc = [0.5268,0.5211,0.5501,0.5672,0.5776,0.5802]\n",
    "std_Test_acc = [0.2125,0.244,0.313,0.3255,0.364,0.3715]\n",
    "Train_data = [normal_Train_acc,incpos_Train_acc,std_Train_acc]\n",
    "Test_data = [normal_Test_acc,incpos_Test_acc,std_Test_acc]\n",
    "margin = 0.2\n",
    "totoal_width = 1 - margin\n",
    "\n",
    "for i,h in enumerate(Train_data):\n",
    "    pos = x - totoal_width *( 1- (2*i+1)/len(Train_data) )/2\n",
    "    plt.bar(pos, h, width = totoal_width/len(Train_data))\n",
    "plt.xticks(x,x_label)\n",
    "plt.title('Training acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,h in enumerate(Train_data):\n",
    "    pos = x - totoal_width *( 1- (2*i+1)/len(Test_data) )/2\n",
    "    plt.bar(pos, h, width = totoal_width/len(Test_data))\n",
    "plt.xticks(x,x_label)\n",
    "plt.title('Test acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchmodel = GCN()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torchmodel.to(device)\n",
    "optimizer = optim.Adam(torchmodel.parameters(),lr = 0.001)\n",
    "epochs = 15\n",
    "\n",
    "history = {'train_loss':[],'train_acc':[],'test_acc':[]}\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for e in range(epochs):\n",
    "    torchmodel.train()\n",
    "    loss = None\n",
    "\n",
    "    for i,(batched_graph, labels) in enumerate(traindataloader):\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = torchmodel(batched_graph, batched_graph.ndata['feat value'].float())\n",
    "        loss = F.cross_entropy(pred,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #if (i+1) % 10 == 0:\n",
    "        #    print(f'Training log: {e+1} epoch ({(i+1)*200} / 10000 train. data). Loss: {loss.item()}')\n",
    "\n",
    "    history['train_loss'].append(loss.item())\n",
    "\n",
    "    torchmodel.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i,(batched_graph, labels) in enumerate(tqdm(traindataloader)):\n",
    "            batched_graph = batched_graph.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred = torchmodel(batched_graph, batched_graph.ndata['feat value'].float())\n",
    "            correct += (pred.argmax(1) == labels).sum().item()\n",
    "            num_tests += len(labels)\n",
    "\n",
    "    acc = float(correct/num_tests)\n",
    "    history['train_acc'].append(acc)\n",
    "\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i,(batched_graph, labels) in enumerate(tqdm(testdataloader)):\n",
    "            batched_graph = batched_graph.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred = torchmodel(batched_graph, batched_graph.ndata['feat value'].float())\n",
    "            correct += (pred.argmax(1) == labels).sum().item()\n",
    "            num_tests += len(labels)\n",
    "\n",
    "    acc = float(correct/num_tests)\n",
    "    history['test_acc'].append(acc)\n",
    "\n",
    "max_train_acc = max(history['train_acc'])\n",
    "min_train_loss = min(history['train_loss'])\n",
    "max_test_acc = max(history['test_acc'])\n",
    "\n",
    "print(f'Max train accuracy: {max_train_acc}')\n",
    "print(f'Min train loss: {min_train_loss}')\n",
    "print(f'Max test acc: {max_test_acc}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d52d0d992e63df6173dda17786029bd856ebae9589c544f4ff518307d39631f3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('GNN_DGL': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
