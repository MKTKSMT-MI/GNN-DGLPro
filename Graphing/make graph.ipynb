{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# グラフ作成　2022/6/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像を畳み込みして6枚取得  \n",
    "一枚に加算  \n",
    "2次元配列を1次元に変換  \n",
    "配列を小さい順にソート  \n",
    "大きいほうからノード数分の数値のインデックスを取得  \n",
    "取得したインデックスから元の座標を計算  \n",
    "座標から6つの画素値を取得  \n",
    "座標からノード間の距離を計算  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echigo/anaconda3/envs/DGL2/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#必要なパッケージをインポート\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import os\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#CIFAR-10の読み込み\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root = '../data', train = True, download = True, transform = transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='../data',train=False,download=True,transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#畳み込み結果を取得するためのネットワーククラス\n",
    "class Conv_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Dence_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Nested_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_net = Conv_layer()\n",
    "        self.Dence_net = Dence_layer()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv_net(x)\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = self.Dence_net(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#処理を高速化するためにGPUを使用するための設定。モデルをGPUへ\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = Nested_net()\n",
    "model.to(device)\n",
    "\n",
    "#学習済みモデルをロード\n",
    "path = '../models/Nest_model.pth'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(x,y): #距離計算用関数\n",
    "    hdist = ((x[0] - y[0])**2 + (x[1] - y[1])**2)\n",
    "    #hdist = torch.tensor(hdist)\n",
    "    hdist = hdist.clone().detach()\n",
    "    dist = torch.sqrt(hdist)\n",
    "\n",
    "    return dist\n",
    "\n",
    "\n",
    "def return_two_list(node_num):\n",
    "    taikaku = torch.full((node_num,node_num),fill_value=1.)\n",
    "    for i in range(node_num):\n",
    "        taikaku[i][i] = 0.\n",
    "    src_ids = []\n",
    "    dst_ids = []\n",
    "    for i in range(node_num):\n",
    "        for j in range(i,node_num):\n",
    "            if taikaku[i][j] != 0:\n",
    "                src_ids.append(i)\n",
    "                dst_ids.append(j)\n",
    "                src_ids.append(j)\n",
    "                dst_ids.append(i)\n",
    "    tensor_src = torch.tensor(src_ids)\n",
    "    tensor_dst = torch.tensor(dst_ids)\n",
    "    return tensor_src,tensor_dst\n",
    "\n",
    "    \n",
    "def zscore(x,axis = 0):\n",
    "    stddev, mean = torch.std_mean(x,dim=axis,unbiased=True)\n",
    "    result = (x - mean)/stddev\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.ノード特徴量：画素値　エッジ特徴量：距離  \n",
    "2.ノード特徴量：距離　　エッジ特徴量：なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#設定\n",
    "pool = nn.MaxPool2d(2,2)\n",
    "train_data_number = 'full' #0~5000 or full\n",
    "num_node = 5\n",
    "graph_type = 1 #1(n:feat value, e:distance) or 2(n:distance, e:none)\n",
    "mode = None\n",
    "save1_file_name = f'{mode}_6feat_dist_{num_node}.dgl'\n",
    "save2_file_name = f'{mode}_dist_{num_node}.dgl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]/tmp/ipykernel_18411/580188855.py:42: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = sort_index[-num_node:][i] // image_size\n",
      "  0%|          | 0/50000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[13., 23.],\n",
      "        [17., 23.],\n",
      "        [13., 22.],\n",
      "        [16.,  8.],\n",
      "        [15.,  8.]], device='cuda:0')\n",
      "[tensor(4., device='cuda:0'), tensor(1., device='cuda:0'), tensor(15.2971, device='cuda:0'), tensor(15.1327, device='cuda:0'), tensor(4.1231, device='cuda:0'), tensor(15.0333, device='cuda:0'), tensor(15.1327, device='cuda:0'), tensor(14.3178, device='cuda:0'), tensor(14.1421, device='cuda:0'), tensor(1., device='cuda:0')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "graphs = []\n",
    "labels = []\n",
    "class_counter = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0} #カウント用辞書\n",
    "train_class_counter = {0:train_data_number,1:train_data_number,2:train_data_number,3:train_data_number,4:train_data_number,\n",
    "                       5:train_data_number,6:train_data_number,7:train_data_number,8:train_data_number,9:train_data_number}\n",
    "src,dst = return_two_list(num_node)\n",
    "\n",
    "#train start\n",
    "mode = 'train'\n",
    "if type(train_data_number) is int:\n",
    "    check = True\n",
    "    flag = False\n",
    "else:\n",
    "    check = False\n",
    "for image,label in tqdm(trainset):\n",
    "    if check == True:\n",
    "        if class_counter == train_class_counter:\n",
    "            break\n",
    "        if class_counter[label] == train_data_number:\n",
    "            continue\n",
    "        else:\n",
    "            class_counter[label] += 1\n",
    "    image = image.to(device)\n",
    "    image = image.unsqueeze(0)\n",
    "    features_maps = F.relu(model.conv_net.conv1(image))#BCSS\n",
    "    image_size = features_maps.shape[2]\n",
    "    #print(features_maps.shape)\n",
    "    features_maps = features_maps.permute(1,2,3,0)#CSSB\n",
    "    #print(features_maps.shape)\n",
    "    synthetic_map = 0\n",
    "    for i in features_maps:#SSC\n",
    "        synthetic_map += i\n",
    "    #print(synthetic_map.shape)\n",
    "    synthetic_map = torch.squeeze(synthetic_map)\n",
    "    zero2one_map = synthetic_map/torch.max(synthetic_map)\n",
    "    onedim = zero2one_map.reshape(image_size * image_size)\n",
    "    #print(onedim.shape)\n",
    "    sort_onedim,sort_index = torch.sort(onedim)\n",
    "    #print(sort_onedim[-5:],sort_index[-5:])\n",
    "    ori_index = torch.empty(num_node,2,dtype=torch.float32,device=device)\n",
    "    for i in range(num_node):\n",
    "        x = sort_index[-num_node:][i] // image_size\n",
    "        y = sort_index[-num_node:][i] - x * image_size\n",
    "        ori_index[i][0] = x\n",
    "        ori_index[i][1] = y\n",
    "    print(ori_index)\n",
    "    distance = []\n",
    "    for i in range(num_node-1):\n",
    "        for j in range(i+1,num_node):\n",
    "            distance.append(get_distance(ori_index[i],ori_index[j]))\n",
    "    print(distance)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]/tmp/ipykernel_3776/50535596.py:45: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = sort_index[-num_node:][i] // image_size\n",
      "  5%|▌         | 2602/50000 [04:28<13:35:07,  1.03s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "graphs = []\n",
    "labels = []\n",
    "class_counter = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0} #カウント用辞書\n",
    "train_class_counter = {0:train_count,1:train_count,2:train_count,3:train_count,4:train_count,5:train_count,6:train_count,7:train_count,8:train_count,9:train_count} #トレーニング用比較辞書\n",
    "test_class_counter = {0:200,1:200,2:200,3:200,4:200,5:200,6:200,7:200,8:200,9:200} #テスト用比較辞書\n",
    "src,dst = return_two_list(num_node)\n",
    "\n",
    "for img_idx in tqdm(range(50000)):\n",
    "    image, label = trainset[img_idx]\n",
    "    '''\n",
    "    if class_counter == train_class_counter: #クラスカウントチェック\n",
    "        break\n",
    "    if class_counter[label] == train_count:\n",
    "        continue\n",
    "    else:\n",
    "        class_counter[label] += 1\n",
    "    '''\n",
    "    class_counter[label] += 1\n",
    "    image = image.to(device)\n",
    "\n",
    "    image = image.unsqueeze(0) #バッチ用次元を追加\n",
    "    features_maps = F.relu(model.conv_net.conv1(image)) #特徴マップの生成(torch.Size([1, 6, 14, 14]))\n",
    "    image_size = features_maps.shape[2]\n",
    "    #print(features_maps.shape)\n",
    "    features_maps = features_maps.permute(1,2,3,0) #torch.Size([6, 14, 14, 1])\n",
    "\n",
    "    synthetic_map = 0 #合成した特徴マップ\n",
    "    for i in range(len(features_maps)): #6枚を1枚へ合成\n",
    "        synthetic_map += features_maps[i]\n",
    "    \n",
    "    #zero2one_map = synthetic_map / synthetic_map.max() #合成したものを0-1に変換\n",
    "    zero2one_map = zscore(synthetic_map)\n",
    "\n",
    "    onedim = zero2one_map.reshape(image_size*image_size) #0-1画像を14*14の一次元配列に変換\n",
    "    \n",
    "    sort_onedim, sort_index = torch.sort(onedim) #小さい順に並べ替え\n",
    "\n",
    "    ori_index = torch.empty(num_node,2,dtype=torch.float32,device=device) #元の2次元配列においての座標リスト\n",
    "    for i in range(num_node):\n",
    "        x = sort_index[-num_node:][i] // image_size\n",
    "        y = sort_index[-num_node:][i] - x * image_size\n",
    "        ori_index[i][0] = x\n",
    "        ori_index[i][1] = y\n",
    "\n",
    "    '''\n",
    "    node_data = torch.empty([num_node,2],device=device) #座標のみ\n",
    "    node_data = ori_index\n",
    "    '''\n",
    "    \n",
    "\n",
    "    std_index = ori_index / image_size\n",
    "    node_data = torch.empty([num_node,8],device=device) #各画素値6つ + 座標2つ\n",
    "    for i in range(num_node):\n",
    "        six_f = torch.empty(8,device = device)\n",
    "        for j in range(6): #画素値代入\n",
    "            x = int(ori_index[i][0].item())\n",
    "            y = int(ori_index[i][1].item())\n",
    "            six_f[j] = features_maps[j][x][y]\n",
    "        for ind,j in enumerate(range(6,8)): #座標代入\n",
    "            six_f[j] = std_index[i][ind]\n",
    "        node_data[i] = six_f\n",
    "    \n",
    "    \n",
    "    edge_data = torch.empty([num_node * (num_node -1),1],device=device) #エッジデータの作成 10エッジx双方向 = 20個\n",
    "    for i,comb in enumerate(itertools.combinations(ori_index,2)):\n",
    "        d = get_distance(comb[0],comb[1])\n",
    "        edge_data[i*2] = d\n",
    "        edge_data[i*2 + 1] = d\n",
    "\n",
    "    edge_data = zscore(edge_data) #距離の標準化\n",
    "    \n",
    "\n",
    "    #グラフ作成\n",
    "    g = dgl.graph((src,dst),num_nodes=num_node,device=device)\n",
    "    g.edata['distance'] = edge_data #エッジ特徴の代入\n",
    "    g.ndata['feat value'] = node_data #ノード特徴の代入\n",
    "\n",
    "    #保存用リストに追加\n",
    "    graphs.append(g)\n",
    "    labels.append(label)\n",
    "print(len(graphs))\n",
    "print(len(labels))\n",
    "print(class_counter)\n",
    "print(f'ノード数: {num_node}')\n",
    "output_labels = {'label':torch.tensor(labels)}\n",
    "path = f'../data/MyDataset/train_graphs_six_f_in_pos_{num_node}_std_full.dgl'\n",
    "dgl.save_graphs(path,g_list=graphs,labels=output_labels)\n",
    "#テスト用グラフ作成本番用セル。ノードデータは6枚の特徴マップの対応する画素値\n",
    "\n",
    "pool = nn.MaxPool2d(2,2)  #MaxPooling層の設定\n",
    "graphs = []\n",
    "labels = []\n",
    "#num_node = 40\n",
    "class_counter = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0} #カウント用辞書\n",
    "train_class_counter = {0:1000,1:1000,2:1000,3:1000,4:1000,5:1000,6:1000,7:1000,8:1000,9:1000} #トレーニング用比較辞書\n",
    "test_class_counter = {0:200,1:200,2:200,3:200,4:200,5:200,6:200,7:200,8:200,9:200} #テスト用比較辞書\n",
    "\n",
    "src,dst = return_two_list(num_node)\n",
    "for img_idx in tqdm(range(10000)):\n",
    "    image, label = testset[img_idx]\n",
    "\n",
    "    '''\n",
    "    if class_counter == test_class_counter: #クラスカウントチェック\n",
    "        break\n",
    "    if class_counter[label] == 200:\n",
    "        continue\n",
    "    else:\n",
    "        class_counter[label] += 1\n",
    "    '''\n",
    "    class_counter[label] += 1\n",
    "    image = image.to(device)\n",
    "\n",
    "    image = image.unsqueeze(0) #バッチ用次元を追加\n",
    "    features_maps = F.relu(model.conv_net.conv1(image)) #特徴マップの生成(torch.Size([1, 6, 14, 14]))\n",
    "    image_size = features_maps.shape[2]\n",
    "    #print(features_maps.shape)\n",
    "    features_maps = features_maps.permute(1,2,3,0) #torch.Size([6, 14, 14, 1])\n",
    "\n",
    "    synthetic_map = 0 #合成した特徴マップ\n",
    "    for i in range(len(features_maps)): #6枚を1枚へ合成\n",
    "        synthetic_map += features_maps[i]\n",
    "    \n",
    "    #zero2one_map = synthetic_map / synthetic_map.max() #合成したものを0-1に変換\n",
    "    zero2one_map = zscore(synthetic_map)\n",
    "\n",
    "    onedim = zero2one_map.reshape(image_size*image_size) #0-1画像を14*14の一次元配列に変換\n",
    "    \n",
    "    sort_onedim, sort_index = torch.sort(onedim) #小さい順に並べ替え\n",
    "\n",
    "    ori_index = torch.empty(num_node,2,dtype=torch.float32,device=device) #元の2次元配列においての座標リスト\n",
    "    for i in range(num_node):\n",
    "        x = sort_index[-num_node:][i] // image_size\n",
    "        y = sort_index[-num_node:][i] - x * image_size\n",
    "        ori_index[i][0] = x\n",
    "        ori_index[i][1] = y\n",
    "    \n",
    "    '''\n",
    "    node_data = torch.empty([num_node,2],device=device)\n",
    "    node_data = ori_index\n",
    "    '''\n",
    "    \n",
    "    std_index = ori_index / image_size\n",
    "    node_data = torch.empty([num_node,8],device=device)\n",
    "    for i in range(num_node):\n",
    "        six_f = torch.empty(8,device = device)\n",
    "        for j in range(6):\n",
    "            x = int(ori_index[i][0].item())\n",
    "            y = int(ori_index[i][1].item())\n",
    "            six_f[j] = features_maps[j][x][y]\n",
    "        for ind,j in enumerate(range(6,8)): #座標代入\n",
    "            six_f[j] = std_index[i][ind]\n",
    "        node_data[i] = six_f\n",
    "    \n",
    "    \n",
    "    edge_data = torch.empty([num_node * (num_node - 1),1],device=device) #エッジデータの作成 10エッジx双方向 = 20個\n",
    "    for i,comb in enumerate(itertools.combinations(ori_index,2)):\n",
    "        d = get_distance(comb[0],comb[1])\n",
    "        edge_data[i*2] = d\n",
    "        edge_data[i*2 + 1] = d\n",
    "\n",
    "    edge_data = zscore(edge_data)\n",
    "\n",
    "    #グラフ作成\n",
    "    g = dgl.graph((src,dst),num_nodes=num_node,device=device)\n",
    "    g.edata['distance'] = edge_data #エッジ特徴の代入\n",
    "    g.ndata['feat value'] = node_data #ノード特徴の代入\n",
    "\n",
    "    #保存用リストに追加\n",
    "    graphs.append(g)\n",
    "    labels.append(label)\n",
    "print(len(graphs))\n",
    "print(len(labels))\n",
    "print(class_counter)\n",
    "print(f'ノード数: {num_node}')\n",
    "output_labels = {'label':torch.tensor(labels)}\n",
    "path = f'../data/MyDataset/test_graphs_six_f_in_pos_{num_node}_std_full.dgl'\n",
    "dgl.save_graphs(path,g_list=graphs,labels=output_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bae489d056b3b2fb3da90055ea9058b18f6663cd5fc5b4a870a71c1d277c079c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('DGL2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
