{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# グラフ作成　2022/6/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像を畳み込みして6枚取得  \n",
    "一枚に加算  \n",
    "2次元配列を1次元に変換  \n",
    "配列を小さい順にソート  \n",
    "大きいほうからノード数分の数値のインデックスを取得  \n",
    "取得したインデックスから元の座標を計算  \n",
    "座標から6つの画素値を取得  \n",
    "座標からノード間の距離を計算  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#必要なパッケージをインポート\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import os\n",
    "import itertools\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#CIFAR-10の読み込み\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root = '../data', train = True, download = True, transform = transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='../data',train=False,download=True,transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#畳み込み結果を取得するためのネットワーククラス\n",
    "class Conv_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Dence_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Nested_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_net = Conv_layer()\n",
    "        self.Dence_net = Dence_layer()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv_net(x)\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = self.Dence_net(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#処理を高速化するためにGPUを使用するための設定。モデルをGPUへ\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = Nested_net()\n",
    "model.to(device)\n",
    "\n",
    "#学習済みモデルをロード\n",
    "path = '../models/Nest_model.pth'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(x,y): #距離計算用関数\n",
    "    hdist = ((x[0] - y[0])**2 + (x[1] - y[1])**2)\n",
    "    #hdist = torch.tensor(hdist)\n",
    "    hdist = hdist.clone().detach()\n",
    "    dist = torch.sqrt(hdist)\n",
    "\n",
    "    return dist\n",
    "\n",
    "\n",
    "def return_two_list(node_num):\n",
    "    taikaku = torch.full((node_num,node_num),fill_value=1.)\n",
    "    for i in range(node_num):\n",
    "        taikaku[i][i] = 0.\n",
    "    src_ids = []\n",
    "    dst_ids = []\n",
    "    for i in range(node_num):\n",
    "        for j in range(i,node_num):\n",
    "            if taikaku[i][j] != 0:\n",
    "                src_ids.append(i)\n",
    "                dst_ids.append(j)\n",
    "                src_ids.append(j)\n",
    "                dst_ids.append(i)\n",
    "    tensor_src = torch.tensor(src_ids)\n",
    "    tensor_dst = torch.tensor(dst_ids)\n",
    "    return tensor_src,tensor_dst\n",
    "\n",
    "    \n",
    "def zscore(x,axis = 0):\n",
    "    stddev, mean = torch.std_mean(x,dim=axis,unbiased=True)\n",
    "    result = (x - mean)/stddev\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.ノード特徴量：画素値　エッジ特徴量：距離  \n",
    "2.ノード特徴量：距離　　エッジ特徴量：なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#設定\n",
    "pool = nn.MaxPool2d(2,2)\n",
    "train_data_number = 2000 #0~5000 or full\n",
    "num_node = 40\n",
    "graph_type = 2 #1(n:feat value, e:distance) or 2(n:distance, e:none)\n",
    "mode = None\n",
    "save1_file_name = f'{mode}_6feat_dist_{num_node}.dgl'\n",
    "save2_file_name = f'{mode}_dist_{num_node}.dgl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]C:\\Users\\kisim\\AppData\\Local\\Temp\\ipykernel_25712\\1412978151.py:43: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = sort_index[-num_node:][i] // image_size\n",
      " 42%|████▏     | 20808/50000 [22:11<31:08, 15.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "20000\n",
      "{0: 2000, 1: 2000, 2: 2000, 3: 2000, 4: 2000, 5: 2000, 6: 2000, 7: 2000, 8: 2000, 9: 2000}\n",
      "ノード数: 40\n"
     ]
    }
   ],
   "source": [
    "graphs = []\n",
    "labels = []\n",
    "class_counter = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0} #カウント用辞書\n",
    "train_class_counter = {0:train_data_number,1:train_data_number,2:train_data_number,3:train_data_number,4:train_data_number,\n",
    "                       5:train_data_number,6:train_data_number,7:train_data_number,8:train_data_number,9:train_data_number}\n",
    "src,dst = return_two_list(num_node)\n",
    "\n",
    "#train start\n",
    "mode = 'train'\n",
    "if type(train_data_number) is int:\n",
    "    check = True\n",
    "    flag = False\n",
    "else:\n",
    "    check = False\n",
    "for image,label in tqdm(trainset):\n",
    "    if check == True:\n",
    "        if class_counter == train_class_counter:\n",
    "            break\n",
    "        if class_counter[label] == train_data_number:\n",
    "            continue\n",
    "        else:\n",
    "            class_counter[label] += 1\n",
    "    image = image.to(device)\n",
    "    image = image.unsqueeze(0)\n",
    "    features_maps = F.relu(model.conv_net.conv1(image))#BCSS\n",
    "    image_size = features_maps.shape[2]\n",
    "    #print(features_maps.shape)\n",
    "    features_maps = features_maps.permute(1,2,3,0)#CSSB\n",
    "    #print(features_maps.shape)\n",
    "    synthetic_map = 0\n",
    "    for i in features_maps:#SSC\n",
    "        synthetic_map += i\n",
    "    features_maps = torch.squeeze(features_maps)\n",
    "    #print(features_maps.shape)\n",
    "    synthetic_map = torch.squeeze(synthetic_map)#SS\n",
    "    zero2one_map = synthetic_map/torch.max(synthetic_map)\n",
    "    onedim = zero2one_map.reshape(image_size * image_size)\n",
    "    #print(onedim.shape)\n",
    "    sort_onedim,sort_index = torch.sort(onedim)\n",
    "    #print(sort_onedim[-5:],sort_index[-5:])\n",
    "    ori_index = torch.empty(num_node,2,dtype=torch.float32,device=device)\n",
    "    for i in range(num_node):\n",
    "        x = sort_index[-num_node:][i] // image_size\n",
    "        y = sort_index[-num_node:][i] - x * image_size\n",
    "        ori_index[i][0] = x\n",
    "        ori_index[i][1] = y\n",
    "    #print(ori_index)\n",
    "    distance = []\n",
    "    for i in range(num_node-1):\n",
    "        for j in range(i+1,num_node):\n",
    "            distance.append(get_distance(ori_index[i],ori_index[j]))\n",
    "    distance = torch.tensor(distance,device=device)\n",
    "    #print(distance)\n",
    "    if graph_type == 1:\n",
    "        node_data = torch.empty([num_node,6],device=device)\n",
    "        for i in range(num_node):\n",
    "            for j in range(6):\n",
    "                x = int(ori_index[i][0].item())\n",
    "                y = int(ori_index[i][1].item())\n",
    "                node_data[i][j] = features_maps[j][x][y]\n",
    "        #print(node_data)\n",
    "        edge_data = torch.empty([num_node * (num_node - 1),1],device=device)\n",
    "        for i,dis in enumerate(distance):\n",
    "            edge_data[i*2] = dis\n",
    "            edge_data[i*2+1] = dis\n",
    "        #print(edge_data)\n",
    "\n",
    "        g = dgl.graph((src,dst),num_nodes=num_node,device=device)\n",
    "        g.ndata['feat value'] = node_data\n",
    "        g.edata['distance'] = edge_data\n",
    "        graphs.append(g)\n",
    "        labels.append(label)\n",
    "    elif graph_type == 2:\n",
    "        #distance = distance / torch.max(distance)\n",
    "        node_data = torch.zeros([num_node,num_node],device=device)\n",
    "        d = 0\n",
    "        for i in range(num_node - 1):\n",
    "            node_data[i][i+1:num_node] = distance[d:d + (num_node -1)+i*-1]\n",
    "            d = d + (num_node -1)+i*-1\n",
    "        node_data = node_data + torch.transpose(node_data,0,1)\n",
    "        #print(node_data)\n",
    "\n",
    "        g = dgl.graph((src,dst),num_nodes=num_node,device=device)\n",
    "        g.ndata['feat value'] = node_data\n",
    "        graphs.append(g)\n",
    "        labels.append(label)\n",
    "    else:\n",
    "        print('graph_typeの指定が不正。終了します。')\n",
    "        sys.exit()\n",
    "print(len(graphs))\n",
    "print(len(labels))\n",
    "print(class_counter)\n",
    "print(f'ノード数: {num_node}')\n",
    "output_labels = {'label':torch.tensor(labels)}\n",
    "if graph_type == 1:\n",
    "    path = f'../data/NewMyData/{mode}_6feat_dist_{num_node}.dgl'\n",
    "elif graph_type == 2:\n",
    "    path = f'../data/NewMyData/{mode}_dist_{num_node}_std.dgl'\n",
    "dgl.save_graphs(path,g_list=graphs,labels=output_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]C:\\Users\\kisim\\AppData\\Local\\Temp\\ipykernel_25712\\1644595542.py:29: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = sort_index[-num_node:][i] // image_size\n",
      "100%|██████████| 10000/10000 [11:33<00:00, 14.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "{0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000, 9: 1000}\n",
      "ノード数: 40\n"
     ]
    }
   ],
   "source": [
    "graphs = []\n",
    "labels = []\n",
    "class_counter = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0} #カウント用辞書\n",
    "src,dst = return_two_list(num_node)\n",
    "\n",
    "#train start\n",
    "mode = 'test'\n",
    "for image,label in tqdm(testset):\n",
    "    class_counter[label] += 1\n",
    "    image = image.to(device)\n",
    "    image = image.unsqueeze(0)\n",
    "    features_maps = F.relu(model.conv_net.conv1(image))#BCSS\n",
    "    image_size = features_maps.shape[2]\n",
    "    #print(features_maps.shape)\n",
    "    features_maps = features_maps.permute(1,2,3,0)#CSSB\n",
    "\n",
    "    synthetic_map = 0\n",
    "    for i in features_maps:#SSC\n",
    "        synthetic_map += i\n",
    "    features_maps = torch.squeeze(features_maps)\n",
    "    synthetic_map = torch.squeeze(synthetic_map)#SS\n",
    "    zero2one_map = synthetic_map/torch.max(synthetic_map)\n",
    "    onedim = zero2one_map.reshape(image_size * image_size)\n",
    "    #print(onedim.shape)\n",
    "    sort_onedim,sort_index = torch.sort(onedim)\n",
    "    #print(sort_onedim[-5:],sort_index[-5:])\n",
    "    ori_index = torch.empty(num_node,2,dtype=torch.float32,device=device)\n",
    "    for i in range(num_node):\n",
    "        x = sort_index[-num_node:][i] // image_size\n",
    "        y = sort_index[-num_node:][i] - x * image_size\n",
    "        ori_index[i][0] = x\n",
    "        ori_index[i][1] = y\n",
    "\n",
    "    distance = []\n",
    "    for i in range(num_node-1):\n",
    "        for j in range(i+1,num_node):\n",
    "            distance.append(get_distance(ori_index[i],ori_index[j]))\n",
    "    distance = torch.tensor(distance,device=device)\n",
    " \n",
    "    if graph_type == 1:\n",
    "        node_data = torch.empty([num_node,6],device=device)\n",
    "        for i in range(num_node):\n",
    "            for j in range(6):\n",
    "                x = int(ori_index[i][0].item())\n",
    "                y = int(ori_index[i][1].item())\n",
    "                node_data[i][j] = features_maps[j][x][y]\n",
    "\n",
    "        edge_data = torch.empty([num_node * (num_node - 1),1],device=device)\n",
    "        for i,dis in enumerate(distance):\n",
    "            edge_data[i*2] = dis\n",
    "            edge_data[i*2+1] = dis\n",
    "\n",
    "        g = dgl.graph((src,dst),num_nodes=num_node,device=device)\n",
    "        g.ndata['feat value'] = node_data\n",
    "        g.edata['distance'] = edge_data\n",
    "        graphs.append(g)\n",
    "        labels.append(label)\n",
    "\n",
    "    elif graph_type == 2:\n",
    "        #distance = distance / torch.max(distance)\n",
    "        node_data = torch.zeros([num_node,num_node],device=device)\n",
    "        d = 0\n",
    "        for i in range(num_node - 1):\n",
    "            node_data[i][i+1:num_node] = distance[d:d + (num_node -1)+i*-1]\n",
    "            d = d + (num_node -1)+i*-1\n",
    "        node_data = node_data + torch.transpose(node_data,0,1)\n",
    "        \n",
    "        g = dgl.graph((src,dst),num_nodes=num_node,device=device)\n",
    "        g.ndata['feat value'] = node_data\n",
    "        graphs.append(g)\n",
    "        labels.append(label)\n",
    "\n",
    "    else:\n",
    "        print('graph_typeの指定が不正。終了します。')\n",
    "        sys.exit()\n",
    "\n",
    "print(len(graphs))\n",
    "print(len(labels))\n",
    "print(class_counter)\n",
    "print(f'ノード数: {num_node}')\n",
    "output_labels = {'label':torch.tensor(labels)}\n",
    "if graph_type == 1:\n",
    "    path = f'../data/NewMyData/{mode}_6feat_dist_{num_node}.dgl'\n",
    "elif graph_type == 2:\n",
    "    path = f'../data/NewMyData/{mode}_dist_{num_node}.dgl'\n",
    "dgl.save_graphs(path,g_list=graphs,labels=output_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('GDW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9512f24219e729098bc0f30caa9285407db90c80b780d5e3a7fd78ad6fa2427c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
