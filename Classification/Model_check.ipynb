{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.data\n",
    "from dgl.nn import GraphConv,MaxPooling\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STL10TrainDataset(DGLDataset):\n",
    "    def __init__(self,data_path,transforms=None):\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "        super().__init__(name='stl10_train_gprah')\n",
    "    \n",
    "    def process(self):\n",
    "        GRAPHS, LABELS = dgl.load_graphs(self.data_path) #保存したグラーフデータの読み込み\n",
    "        self.graphs = GRAPHS #グラフリストを代入\n",
    "        self.labels = LABELS['label'] #ラベル辞書の値のみ代入\n",
    "        self.dim_nfeats=len(self.graphs[0].ndata['feat'][0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transforms == None:\n",
    "            return self.graphs[idx], self.labels[idx]\n",
    "        else:\n",
    "            data=self.transforms(self.graphs[idx])\n",
    "            return data,self.labels[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "\n",
    "class STL10TestDataset(DGLDataset):\n",
    "    def __init__(self,data_path,transforms=None):\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "        super().__init__(name='stl10_test_gprah')\n",
    "    \n",
    "    def process(self):\n",
    "        GRAPHS, LABELS = dgl.load_graphs(self.data_path) #保存したグラーフデータの読み込み\n",
    "        self.graphs = GRAPHS #グラフリストを代入\n",
    "        self.labels = LABELS['label'] #ラベル辞書の値のみ代入\n",
    "        self.dim_nfeats=len(self.graphs[0].ndata['feat'][0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transforms == None:\n",
    "            return self.graphs[idx], self.labels[idx]\n",
    "        else:\n",
    "            data=self.transforms(self.graphs[idx])\n",
    "            return data,self.labels[idx]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''class DynamicGCN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(DynamicGCN,self).__init__()\n",
    "        self.input_layer=GraphConv(input_size,hidden_size[0])\n",
    "        self.middle_layers=nn.ModuleList([GraphConv(hidden_size[i],hidden_size[i+1]) for i in range(len(hidden_size)-1)])\n",
    "        self.output_layer=GraphConv(hidden_size[-1],output_size)\n",
    "        self.m=nn.LeakyReLU()\n",
    "\n",
    "        self.flatt=nn.Flatten()\n",
    "\n",
    "    \n",
    "    def forward(self,g,n_feat,e_feat=None):\n",
    "        n_feat=self.flatt(n_feat)\n",
    "        h=self.input_layer(g,n_feat,None,e_feat).clamp(0)\n",
    "        for layer in self.middle_layers:\n",
    "            h=layer(g,h)\n",
    "            h=self.m(h)\n",
    "        h=self.output_layer(g,h).clamp(0)\n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        return dgl.mean_nodes(g,'h')'''\n",
    "class DynamicGCN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(DynamicGCN,self).__init__()\n",
    "        self.input_layer=GraphConv(input_size,hidden_size[0])\n",
    "        self.middle_layers=nn.ModuleList([GraphConv(hidden_size[i],hidden_size[i+1]) for i in range(len(hidden_size)-1)])\n",
    "        self.output_layer=GraphConv(hidden_size[-1],output_size)\n",
    "\n",
    "        self.flatt=nn.Flatten()\n",
    "\n",
    "    \n",
    "    def forward(self,g,n_feat,e_feat=None):\n",
    "        n_feat=self.flatt(n_feat)\n",
    "        h=self.input_layer(g,n_feat,None,e_feat).clamp(0)\n",
    "        for layer in self.middle_layers:\n",
    "            h=layer(g,h).clamp(0)\n",
    "        h=self.output_layer(g,h).clamp(0)\n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        return dgl.mean_nodes(g,'h')\n",
    "    \n",
    "\n",
    "class PatchGCN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size,linear=False):\n",
    "        super(PatchGCN,self).__init__()\n",
    "        self.linear_on = True\n",
    "        self.input_layer=GraphConv(input_size,hidden_size[0])\n",
    "        self.middle_layers=nn.ModuleList([GraphConv(hidden_size[i],hidden_size[i+1]) for i in range(len(hidden_size)-1)])\n",
    "        self.output_layer=GraphConv(hidden_size[-1],output_size)\n",
    "        if self.linear_on:\n",
    "            self.linear_layers=nn.ModuleList([nn.Linear(hidden_size[i],hidden_size[i]) for i in range(len(hidden_size))])\n",
    "        self.m=nn.LeakyReLU()\n",
    "\n",
    "        self.flatt=nn.Flatten()\n",
    "\n",
    "    \n",
    "    def forward(self,g,n_feat,e_feat=None):\n",
    "        n_feat=self.flatt(n_feat)\n",
    "        h=self.input_layer(g,n_feat,None,e_feat).clamp(0)\n",
    "        for i,layer in enumerate(self.middle_layers):\n",
    "            if self.linear_on:\n",
    "                skip=h\n",
    "                h=self.linear_layers[i](h)\n",
    "                h=h+skip\n",
    "            h=layer(g,h)\n",
    "            h=self.m(h)\n",
    "        h=self.output_layer(g,h).clamp(0)\n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        return dgl.mean_nodes(g,'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/DGL/lib/python3.8/site-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DGL/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'n_feat'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4883/3453997955.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPatchGCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2352\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/DGL/lib/python3.8/site-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     )\n\u001b[0;32m--> 223\u001b[0;31m     summary_list = forward_pass(\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_forward_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/envs/DGL/lib/python3.8/site-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mexecuted_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummary_list\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuted\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0;34m\"Failed to run torchinfo. See above stack traces for more details. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;34mf\"Executed layers up to: {executed_layers}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "batch_size=512\n",
    "summary(model=PatchGCN(2352,[2000,2000,1000],10),input_size=(batch_size,64,3,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform = transforms.Compose([transforms.Normalize(0,1)])\n",
    "traindataset=STL10TrainDataset('../data/STL10 Datasets/train/nnum20_ndatapic9_enone_akaze.dgl')\n",
    "testdataset=STL10TestDataset('../data/STL10 Datasets/test/nnum20_ndatapic9_enone_akaze.dgl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_wokers = 0\n",
      "posix\n"
     ]
    }
   ],
   "source": [
    "if os.name =='posix':\n",
    "    num_workers = 2\n",
    "else:\n",
    "    num_workers = 0\n",
    "num_workers = 0\n",
    "traindataloader = GraphDataLoader(traindataset,batch_size = 512,shuffle = True,num_workers = num_workers,pin_memory = True)\n",
    "testdataloader = GraphDataLoader(testdataset,batch_size = 1000,shuffle = True,num_workers = num_workers,pin_memory = True)\n",
    "print(f'num_wokers = {num_workers}')\n",
    "print(os.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Test accuracy: 0.10015003750937734\n"
     ]
    }
   ],
   "source": [
    "#テストラスト\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_path='save/nnum20_ndatapic9_enone_akaze.dgl/config1-2.yaml/model1/model_weight.pth'\n",
    "print(os.path.isfile(model_path))\n",
    "model=torch.load(model_path,map_location=torch.device('cpu'))\n",
    "model.to(device)\n",
    "\n",
    "test_num_correct = 0\n",
    "test_num_tests = 0\n",
    "save_test_acc=0\n",
    "with torch.no_grad():\n",
    "    #全テストデータでの正答率\n",
    "    model.eval()\n",
    "    for batched_graph, labels in testdataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'])\n",
    "        test_num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "        test_num_tests += len(labels)\n",
    "    print('Test accuracy:', test_num_correct / test_num_tests)\n",
    "    save_test_acc=(test_num_correct / test_num_tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Test accuracy: 0.10015003750937734\n"
     ]
    }
   ],
   "source": [
    "#テストベスト\n",
    "model_path='save/nnum20_ndatapic9_enone_akaze.dgl/config1-2.yaml/model1/best_model_weight.pth'\n",
    "print(os.path.isfile(model_path))\n",
    "model=torch.load(model_path,map_location=torch.device('cpu'))\n",
    "model.to(device)\n",
    "\n",
    "test_num_correct = 0\n",
    "test_num_tests = 0\n",
    "save_test_acc=0\n",
    "with torch.no_grad():\n",
    "    #全テストデータでの正答率\n",
    "    model.eval()\n",
    "    for batched_graph, labels in testdataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'])\n",
    "        test_num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "        test_num_tests += len(labels)\n",
    "    print('Test accuracy:', test_num_correct / test_num_tests)\n",
    "    save_test_acc=(test_num_correct / test_num_tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnum20_ndatapic9_enone_akaze.dgl\n",
      "nnum20_ndatapic21_enone_akaze.dgl\n",
      "nnum50_ndatapic9_enone_akaze.dgl\n",
      "nnum50_ndatapic21_enone_akaze.dgl\n"
     ]
    }
   ],
   "source": [
    "#config -1系のデータ処理\n",
    "#読み込みデータのパス指定\n",
    "data_name=['nnum20_ndatapic9_enone_akaze.dgl',\n",
    "           'nnum20_ndatapic21_enone_akaze.dgl',\n",
    "           'nnum50_ndatapic9_enone_akaze.dgl',\n",
    "           'nnum50_ndatapic21_enone_akaze.dgl']\n",
    "data=np.zeros((8,10))\n",
    "for i,dname in enumerate(data_name): #データセット選択\n",
    "    print(dname)\n",
    "    testdataset=STL10TestDataset(f'../data/STL10 Datasets/test/{dname}')\n",
    "    testdataloader = GraphDataLoader(testdataset,batch_size = 1000,shuffle = True,num_workers = num_workers,pin_memory = True)\n",
    "    for j in range(10): #model指定\n",
    "        data_path=f'save/{dname}/model{j+1}/'\n",
    "        model_path=f'{data_path}/model_weight.pth'\n",
    "        yaml_path=f'{data_path}/acc_result.yaml'\n",
    "        with open(yaml_path,'r') as f:\n",
    "            config=yaml.safe_load(f)\n",
    "        \n",
    "        #yamlからtrainの値を読み込み代入\n",
    "        data[i*2][j]=float(config['train acc'])\n",
    "\n",
    "        #モデルを読み込みテストデータで推論し値を代入\n",
    "        model=torch.load(model_path)\n",
    "        model.to(device)\n",
    "        \n",
    "        test_num_correct = 0\n",
    "        test_num_tests = 0\n",
    "        save_test_acc=0\n",
    "        with torch.no_grad():\n",
    "            #全テストデータでの正答率\n",
    "            model.eval()\n",
    "            for batched_graph, labels in testdataloader:\n",
    "                batched_graph = batched_graph.to(device)\n",
    "                labels = labels.to(device)\n",
    "                pred = model(batched_graph, batched_graph.ndata['feat'])\n",
    "                test_num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "                test_num_tests += len(labels)\n",
    "            save_test_acc=(test_num_correct / test_num_tests)\n",
    "        data[i*2+1][j]=save_test_acc\n",
    "#データフレームを作成しdataを代入してcsvで出力\n",
    "index=['20-9 train','20-9 test','20-21 train','20-21 test','50-9 train','50-9 test','50-21 train','50-21 test']\n",
    "columns=['model1','model2','model3','model4','model5','model6','model7','model8','model9','model10']\n",
    "df=pd.DataFrame(data=data,index=index,columns=columns)\n",
    "df.to_csv('check-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnum20_ndatapic9_enone_akaze.dgl\n",
      "nnum20_ndatapic21_enone_akaze.dgl\n",
      "nnum50_ndatapic9_enone_akaze.dgl\n",
      "nnum50_ndatapic21_enone_akaze.dgl\n"
     ]
    }
   ],
   "source": [
    "#config -2系のデータ処理\n",
    "#読み込みデータのパス指定\n",
    "data_name=['nnum20_ndatapic9_enone_akaze.dgl',\n",
    "           'nnum20_ndatapic21_enone_akaze.dgl',\n",
    "           'nnum50_ndatapic9_enone_akaze.dgl',\n",
    "           'nnum50_ndatapic21_enone_akaze.dgl']\n",
    "data=np.zeros((8,10))\n",
    "for i,dname in enumerate(data_name): #データセット選択\n",
    "    print(dname)\n",
    "    testdataset=STL10TestDataset(f'../data/STL10 Datasets/test/{dname}')\n",
    "    testdataloader = GraphDataLoader(testdataset,batch_size = 1000,shuffle = True,num_workers = num_workers,pin_memory = True)\n",
    "    for j in range(10): #model指定\n",
    "        data_path=f'save/{dname}/config{(i%2)+1}-2.yaml/model{j+1}/'\n",
    "        model_path=f'{data_path}/model_weight.pth'\n",
    "        yaml_path=f'{data_path}/acc_result.yaml'\n",
    "        with open(yaml_path,'r') as f:\n",
    "            config=yaml.safe_load(f)\n",
    "        \n",
    "        #yamlからtrainの値を読み込み代入\n",
    "        data[i*2][j]=float(config['train acc'])\n",
    "\n",
    "        #モデルを読み込みテストデータで推論し値を代入\n",
    "        model=torch.load(model_path)\n",
    "        model.to(device)\n",
    "        \n",
    "        test_num_correct = 0\n",
    "        test_num_tests = 0\n",
    "        save_test_acc=0\n",
    "        with torch.no_grad():\n",
    "            #全テストデータでの正答率\n",
    "            model.eval()\n",
    "            for batched_graph, labels in testdataloader:\n",
    "                batched_graph = batched_graph.to(device)\n",
    "                labels = labels.to(device)\n",
    "                pred = model(batched_graph, batched_graph.ndata['feat'])\n",
    "                test_num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "                test_num_tests += len(labels)\n",
    "            save_test_acc=(test_num_correct / test_num_tests)\n",
    "        data[i*2+1][j]=save_test_acc\n",
    "#データフレームを作成しdataを代入してcsvで出力\n",
    "index=['20-9 train','20-9 test','20-21 train','20-21 test','50-9 train','50-9 test','50-21 train','50-21 test']\n",
    "columns=['model1','model2','model3','model4','model5','model6','model7','model8','model9','model10']\n",
    "df=pd.DataFrame(data=data,index=index,columns=columns)\n",
    "df.to_csv('check-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print((i%2)+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('DGL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b3aaad6f4b476a25b1278d44df95c159668e2b4a4f54834857505f20d9767c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
