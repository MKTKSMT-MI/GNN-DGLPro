{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.data\n",
    "from dgl.nn import GraphConv,MaxPooling\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STL10TrainDataset(DGLDataset):\n",
    "    def __init__(self,data_path,transforms=None):\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "        super().__init__(name='stl10_train_gprah')\n",
    "    \n",
    "    def process(self):\n",
    "        GRAPHS, LABELS = dgl.load_graphs(self.data_path) #保存したグラーフデータの読み込み\n",
    "        self.graphs = GRAPHS #グラフリストを代入\n",
    "        self.labels = LABELS['label'] #ラベル辞書の値のみ代入\n",
    "        self.dim_nfeats=len(self.graphs[0].ndata['feat'][0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transforms == None:\n",
    "            return self.graphs[idx], self.labels[idx]\n",
    "        else:\n",
    "            data=self.transforms(self.graphs[idx])\n",
    "            return data,self.labels[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "\n",
    "class STL10TestDataset(DGLDataset):\n",
    "    def __init__(self,data_path,transforms=None):\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "        super().__init__(name='stl10_test_gprah')\n",
    "    \n",
    "    def process(self):\n",
    "        GRAPHS, LABELS = dgl.load_graphs(self.data_path) #保存したグラーフデータの読み込み\n",
    "        self.graphs = GRAPHS #グラフリストを代入\n",
    "        self.labels = LABELS['label'] #ラベル辞書の値のみ代入\n",
    "        self.dim_nfeats=len(self.graphs[0].ndata['feat'][0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transforms == None:\n",
    "            return self.graphs[idx], self.labels[idx]\n",
    "        else:\n",
    "            data=self.transforms(self.graphs[idx])\n",
    "            return data,self.labels[idx]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''class DynamicGCN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(DynamicGCN,self).__init__()\n",
    "        self.input_layer=GraphConv(input_size,hidden_size[0])\n",
    "        self.middle_layers=nn.ModuleList([GraphConv(hidden_size[i],hidden_size[i+1]) for i in range(len(hidden_size)-1)])\n",
    "        self.output_layer=GraphConv(hidden_size[-1],output_size)\n",
    "        self.m=nn.LeakyReLU()\n",
    "\n",
    "        self.flatt=nn.Flatten()\n",
    "\n",
    "    \n",
    "    def forward(self,g,n_feat,e_feat=None):\n",
    "        n_feat=self.flatt(n_feat)\n",
    "        h=self.input_layer(g,n_feat,None,e_feat).clamp(0)\n",
    "        for layer in self.middle_layers:\n",
    "            h=layer(g,h)\n",
    "            h=self.m(h)\n",
    "        h=self.output_layer(g,h).clamp(0)\n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        return dgl.mean_nodes(g,'h')'''\n",
    "class DynamicGCN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(DynamicGCN,self).__init__()\n",
    "        self.input_layer=GraphConv(input_size,hidden_size[0])\n",
    "        self.middle_layers=nn.ModuleList([GraphConv(hidden_size[i],hidden_size[i+1]) for i in range(len(hidden_size)-1)])\n",
    "        self.output_layer=GraphConv(hidden_size[-1],output_size)\n",
    "\n",
    "        self.flatt=nn.Flatten()\n",
    "\n",
    "    \n",
    "    def forward(self,g,n_feat,e_feat=None):\n",
    "        n_feat=self.flatt(n_feat)\n",
    "        h=self.input_layer(g,n_feat,None,e_feat).clamp(0)\n",
    "        for layer in self.middle_layers:\n",
    "            h=layer(g,h).clamp(0)\n",
    "        h=self.output_layer(g,h).clamp(0)\n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        return dgl.mean_nodes(g,'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform = transforms.Compose([transforms.Normalize(0,1)])\n",
    "traindataset=STL10TrainDataset('../data/STL10 Datasets/train/nnum20_ndatapic9_enone_akaze.dgl')\n",
    "testdataset=STL10TestDataset('../data/STL10 Datasets/test/nnum20_ndatapic9_enone_akaze.dgl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_wokers = 0\n",
      "posix\n"
     ]
    }
   ],
   "source": [
    "if os.name =='posix':\n",
    "    num_workers = 2\n",
    "else:\n",
    "    num_workers = 0\n",
    "num_workers = 0\n",
    "traindataloader = GraphDataLoader(traindataset,batch_size = 512,shuffle = True,num_workers = num_workers,pin_memory = True)\n",
    "testdataloader = GraphDataLoader(testdataset,batch_size = 1000,shuffle = True,num_workers = num_workers,pin_memory = True)\n",
    "print(f'num_wokers = {num_workers}')\n",
    "print(os.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Test accuracy: 0.10015003750937734\n"
     ]
    }
   ],
   "source": [
    "#テストラスト\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_path='save/nnum20_ndatapic9_enone_akaze.dgl/config1-2.yaml/model1/model_weight.pth'\n",
    "print(os.path.isfile(model_path))\n",
    "model=torch.load(model_path,map_location=torch.device('cpu'))\n",
    "model.to(device)\n",
    "\n",
    "test_num_correct = 0\n",
    "test_num_tests = 0\n",
    "save_test_acc=0\n",
    "with torch.no_grad():\n",
    "    #全テストデータでの正答率\n",
    "    model.eval()\n",
    "    for batched_graph, labels in testdataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'])\n",
    "        test_num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "        test_num_tests += len(labels)\n",
    "    print('Test accuracy:', test_num_correct / test_num_tests)\n",
    "    save_test_acc=(test_num_correct / test_num_tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Test accuracy: 0.10015003750937734\n"
     ]
    }
   ],
   "source": [
    "#テストベスト\n",
    "model_path='save/nnum20_ndatapic9_enone_akaze.dgl/config1-2.yaml/model1/best_model_weight.pth'\n",
    "print(os.path.isfile(model_path))\n",
    "model=torch.load(model_path,map_location=torch.device('cpu'))\n",
    "model.to(device)\n",
    "\n",
    "test_num_correct = 0\n",
    "test_num_tests = 0\n",
    "save_test_acc=0\n",
    "with torch.no_grad():\n",
    "    #全テストデータでの正答率\n",
    "    model.eval()\n",
    "    for batched_graph, labels in testdataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'])\n",
    "        test_num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "        test_num_tests += len(labels)\n",
    "    print('Test accuracy:', test_num_correct / test_num_tests)\n",
    "    save_test_acc=(test_num_correct / test_num_tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnum20_ndatapic9_enone_akaze.dgl\n",
      "nnum20_ndatapic21_enone_akaze.dgl\n",
      "nnum50_ndatapic9_enone_akaze.dgl\n",
      "nnum50_ndatapic21_enone_akaze.dgl\n"
     ]
    }
   ],
   "source": [
    "#config -1系のデータ処理\n",
    "#読み込みデータのパス指定\n",
    "data_name=['nnum20_ndatapic9_enone_akaze.dgl',\n",
    "           'nnum20_ndatapic21_enone_akaze.dgl',\n",
    "           'nnum50_ndatapic9_enone_akaze.dgl',\n",
    "           'nnum50_ndatapic21_enone_akaze.dgl']\n",
    "data=np.zeros((8,10))\n",
    "for i,dname in enumerate(data_name): #データセット選択\n",
    "    print(dname)\n",
    "    testdataset=STL10TestDataset(f'../data/STL10 Datasets/test/{dname}')\n",
    "    testdataloader = GraphDataLoader(testdataset,batch_size = 1000,shuffle = True,num_workers = num_workers,pin_memory = True)\n",
    "    for j in range(10): #model指定\n",
    "        data_path=f'save/{dname}/model{j+1}/'\n",
    "        model_path=f'{data_path}/model_weight.pth'\n",
    "        yaml_path=f'{data_path}/acc_result.yaml'\n",
    "        with open(yaml_path,'r') as f:\n",
    "            config=yaml.safe_load(f)\n",
    "        \n",
    "        #yamlからtrainの値を読み込み代入\n",
    "        data[i*2][j]=float(config['train acc'])\n",
    "\n",
    "        #モデルを読み込みテストデータで推論し値を代入\n",
    "        model=torch.load(model_path)\n",
    "        model.to(device)\n",
    "        \n",
    "        test_num_correct = 0\n",
    "        test_num_tests = 0\n",
    "        save_test_acc=0\n",
    "        with torch.no_grad():\n",
    "            #全テストデータでの正答率\n",
    "            model.eval()\n",
    "            for batched_graph, labels in testdataloader:\n",
    "                batched_graph = batched_graph.to(device)\n",
    "                labels = labels.to(device)\n",
    "                pred = model(batched_graph, batched_graph.ndata['feat'])\n",
    "                test_num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "                test_num_tests += len(labels)\n",
    "            save_test_acc=(test_num_correct / test_num_tests)\n",
    "        data[i*2+1][j]=save_test_acc\n",
    "#データフレームを作成しdataを代入してcsvで出力\n",
    "index=['20-9 train','20-9 test','20-21 train','20-21 test','50-9 train','50-9 test','50-21 train','50-21 test']\n",
    "columns=['model1','model2','model3','model4','model5','model6','model7','model8','model9','model10']\n",
    "df=pd.DataFrame(data=data,index=index,columns=columns)\n",
    "df.to_csv('check-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnum20_ndatapic9_enone_akaze.dgl\n",
      "nnum20_ndatapic21_enone_akaze.dgl\n",
      "nnum50_ndatapic9_enone_akaze.dgl\n",
      "nnum50_ndatapic21_enone_akaze.dgl\n"
     ]
    }
   ],
   "source": [
    "#config -2系のデータ処理\n",
    "#読み込みデータのパス指定\n",
    "data_name=['nnum20_ndatapic9_enone_akaze.dgl',\n",
    "           'nnum20_ndatapic21_enone_akaze.dgl',\n",
    "           'nnum50_ndatapic9_enone_akaze.dgl',\n",
    "           'nnum50_ndatapic21_enone_akaze.dgl']\n",
    "data=np.zeros((8,10))\n",
    "for i,dname in enumerate(data_name): #データセット選択\n",
    "    print(dname)\n",
    "    testdataset=STL10TestDataset(f'../data/STL10 Datasets/test/{dname}')\n",
    "    testdataloader = GraphDataLoader(testdataset,batch_size = 1000,shuffle = True,num_workers = num_workers,pin_memory = True)\n",
    "    for j in range(10): #model指定\n",
    "        data_path=f'save/{dname}/config{(i%2)+1}-2.yaml/model{j+1}/'\n",
    "        model_path=f'{data_path}/model_weight.pth'\n",
    "        yaml_path=f'{data_path}/acc_result.yaml'\n",
    "        with open(yaml_path,'r') as f:\n",
    "            config=yaml.safe_load(f)\n",
    "        \n",
    "        #yamlからtrainの値を読み込み代入\n",
    "        data[i*2][j]=float(config['train acc'])\n",
    "\n",
    "        #モデルを読み込みテストデータで推論し値を代入\n",
    "        model=torch.load(model_path)\n",
    "        model.to(device)\n",
    "        \n",
    "        test_num_correct = 0\n",
    "        test_num_tests = 0\n",
    "        save_test_acc=0\n",
    "        with torch.no_grad():\n",
    "            #全テストデータでの正答率\n",
    "            model.eval()\n",
    "            for batched_graph, labels in testdataloader:\n",
    "                batched_graph = batched_graph.to(device)\n",
    "                labels = labels.to(device)\n",
    "                pred = model(batched_graph, batched_graph.ndata['feat'])\n",
    "                test_num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "                test_num_tests += len(labels)\n",
    "            save_test_acc=(test_num_correct / test_num_tests)\n",
    "        data[i*2+1][j]=save_test_acc\n",
    "#データフレームを作成しdataを代入してcsvで出力\n",
    "index=['20-9 train','20-9 test','20-21 train','20-21 test','50-9 train','50-9 test','50-21 train','50-21 test']\n",
    "columns=['model1','model2','model3','model4','model5','model6','model7','model8','model9','model10']\n",
    "df=pd.DataFrame(data=data,index=index,columns=columns)\n",
    "df.to_csv('check-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print((i%2)+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('DGL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b3aaad6f4b476a25b1278d44df95c159668e2b4a4f54834857505f20d9767c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
