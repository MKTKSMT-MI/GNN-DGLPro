{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.data\n",
    "from dgl.nn import GraphConv,MaxPooling\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STL10TrainDataset(DGLDataset):\n",
    "    def __init__(self,data_path):\n",
    "        self.data_path = data_path\n",
    "        super().__init__(name='stl10_train_gprah')\n",
    "    \n",
    "    def process(self):\n",
    "        GRAPHS, LABELS = dgl.load_graphs(self.data_path) #保存したグラーフデータの読み込み\n",
    "        self.graphs = GRAPHS #グラフリストを代入\n",
    "        self.labels = LABELS['label'] #ラベル辞書の値のみ代入\n",
    "        self.dim_nfeats=len(self.graphs[0].ndata['feat'][0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "\n",
    "class STL10TestDataset(DGLDataset):\n",
    "    def __init__(self,data_path):\n",
    "        self.data_path = data_path\n",
    "        super().__init__(name='stl10_test_gprah')\n",
    "    \n",
    "    def process(self):\n",
    "        GRAPHS, LABELS = dgl.load_graphs(self.data_path) #保存したグラーフデータの読み込み\n",
    "        self.graphs = GRAPHS #グラフリストを代入\n",
    "        self.labels = LABELS['label'] #ラベル辞書の値のみ代入\n",
    "        self.dim_nfeats=len(self.graphs[0].ndata['feat'][0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform = transforms.Compose([transforms.Normalize(0,1)])\n",
    "traindataset=STL10TrainDataset('../data/STL10 Datasets/train/nnum100_ndatades_enone.dgl')\n",
    "testdataset=STL10TestDataset('../data/STL10 Datasets/test/nnum100_ndatades_enone.dgl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_wokers = 0\n",
      "posix\n"
     ]
    }
   ],
   "source": [
    "if os.name =='posix':\n",
    "    num_workers = 2\n",
    "else:\n",
    "    num_workers = 0\n",
    "num_workers = 0\n",
    "traindataloader = GraphDataLoader(traindataset,batch_size = 10,shuffle = True,num_workers = num_workers,pin_memory = True)\n",
    "testdataloader = GraphDataLoader(testdataset,batch_size = 10,shuffle = True,num_workers = num_workers,pin_memory = True)\n",
    "print(f'num_wokers = {num_workers}')\n",
    "print(os.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self,in_feat,h_feat,num_classes):\n",
    "        super(GCN,self).__init__()\n",
    "        self.gconv1=GraphConv(in_feat,h_feat)\n",
    "        self.gconv2=GraphConv(h_feat,num_classes)\n",
    "\n",
    "    def forward(self,g,in_feat):\n",
    "        h=self.gconv1(g,in_feat)\n",
    "        h=F.relu(h)\n",
    "        h=self.gconv2(g,h)\n",
    "        g.ndata['h'] = h\n",
    "        return dgl.mean_nodes(g,'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネルがクラッシュしました。エラーの原因を特定するには、セル内のコードを確認してください。詳細については、<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a> をクリックしてください。さらなる詳細については、Jupyter [log] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "print(traindataset.dim_nfeats)\n",
    "model=GCN(traindataset.dim_nfeats,100,10)\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_train_acc = []\n",
    "save_test_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.28it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "test_num_correct = 0\n",
    "test_num_tests = 0\n",
    "lossF = nn.CrossEntropyLoss()\n",
    "#,batched_graph.edata['distance'].float()\n",
    "BP = 0\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    if BP != 0:\n",
    "        break\n",
    "    model.train()\n",
    "    for batched_graph, labels in traindataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "        loss = lossF(pred,labels)\n",
    "        if loss.item() < 0.05:\n",
    "            BP = 0\n",
    "            break\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "        num_tests += len(labels)\n",
    "    loss_list.append(loss.item())\n",
    "    acc_list.append(num_correct / num_tests) #学習中トレーニングacc\n",
    "    \n",
    "    model.eval()\n",
    "    for tbatched_graph, tlabels in testdataloader:\n",
    "        tbatched_graph = tbatched_graph.to(device)\n",
    "        tlabels = tlabels.to(device)\n",
    "        tpred = model(tbatched_graph, tbatched_graph.ndata['feat'])\n",
    "        test_num_correct += (tpred.argmax(1) == tlabels).sum().item()\n",
    "        test_num_tests += len(tlabels)\n",
    "\n",
    "    Tacc = test_num_correct / test_num_tests\n",
    "    #print('Training accuracy:', Tacc)\n",
    "    test_acc_list.append(Tacc) #学習中テストacc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.48514851485148514\n",
      "Test accuracy: 0.19801980198019803\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_tests = 0\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.train()\n",
    "    for batched_graph, labels in traindataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'])\n",
    "        num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "        num_tests += len(labels)\n",
    "    print('Training accuracy:', num_correct / num_tests)\n",
    "    save_train_acc.append(num_correct / num_tests)\n",
    "    num_correct = 0\n",
    "    num_tests = 0\n",
    "    model.eval()\n",
    "    for batched_graph, labels in testdataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "        num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "        num_tests += len(labels)\n",
    "    print('Test accuracy:', num_correct / num_tests)\n",
    "    save_test_acc.append(num_correct / num_tests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('GDW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9512f24219e729098bc0f30caa9285407db90c80b780d5e3a7fd78ad6fa2427c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
