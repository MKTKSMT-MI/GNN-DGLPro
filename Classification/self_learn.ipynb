{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.data\n",
    "from dgl.nn import GraphConv,MaxPooling\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STL10TrainDataset(DGLDataset):\n",
    "    def __init__(self,data_path,transforms=None):\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "        super().__init__(name='stl10_train_gprah')\n",
    "    \n",
    "    def process(self):\n",
    "        GRAPHS, LABELS = dgl.load_graphs(self.data_path) #保存したグラーフデータの読み込み\n",
    "        self.graphs = GRAPHS #グラフリストを代入\n",
    "        self.labels = LABELS['label'] #ラベル辞書の値のみ代入\n",
    "        self.dim_nfeats=len(self.graphs[0].ndata['f'][0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transforms == None:\n",
    "            return self.graphs[idx], self.labels[idx]\n",
    "        else:\n",
    "            data=self.transforms(self.graphs[idx])\n",
    "            return data,self.labels[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "\n",
    "class STL10TestDataset(DGLDataset):\n",
    "    def __init__(self,data_path,transforms=None):\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "        super().__init__(name='stl10_test_gprah')\n",
    "    \n",
    "    def process(self):\n",
    "        GRAPHS, LABELS = dgl.load_graphs(self.data_path) #保存したグラーフデータの読み込み\n",
    "        self.graphs = GRAPHS #グラフリストを代入\n",
    "        self.labels = LABELS['label'] #ラベル辞書の値のみ代入\n",
    "        self.dim_nfeats=len(self.graphs[0].ndata['f'][0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transforms == None:\n",
    "            return self.graphs[idx], self.labels[idx]\n",
    "        else:\n",
    "            data=self.transforms(self.graphs[idx])\n",
    "            return data,self.labels[idx]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfGCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SelfGCN,self).__init__()\n",
    "        self.input_layer=GraphConv(28,10)\n",
    "        self.mid_layer1=GraphConv(512,512)\n",
    "        self.mid_layer2=GraphConv(512,512)\n",
    "        self.mid_layer3=GraphConv(512,512)\n",
    "        self.output_layer=GraphConv(512,10)\n",
    "\n",
    "        self.m=nn.LeakyReLU()\n",
    "\n",
    "        self.flatt=nn.Flatten()\n",
    "\n",
    "    \n",
    "    def forward(self,g,n_feat):\n",
    "        '''h=self.flatt(n_feat)\n",
    "        h=self.input_layer(g,h)\n",
    "        h=self.m(h)\n",
    "\n",
    "        h=self.mid_layer1(g,h)\n",
    "        h=self.m(h)\n",
    "\n",
    "        h=self.mid_layer2(g,h)\n",
    "        h=self.m(h)\n",
    "\n",
    "        h=self.mid_layer3(g,h)\n",
    "        h=self.m(h)\n",
    "\n",
    "        h=self.output_layer(g,h)\n",
    "        h=self.m(h)'''\n",
    "        h=self.input_layer(g,n_feat)\n",
    "        h=torch.mean(h,0)\n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        return dgl.mean_nodes(g,'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='ndata_8patch.dgl'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "traindataset=STL10TrainDataset(f'../data/STL10 Datasets/train/{data_path}')\n",
    "testdataset=STL10TestDataset(f'../data/STL10 Datasets/test/{data_path}')\n",
    "\n",
    "#データローダー作成\n",
    "num_workers=2\n",
    "traindataloader = GraphDataLoader(traindataset,batch_size = 512,shuffle = True,num_workers = num_workers,pin_memory = True)\n",
    "testdataloader = GraphDataLoader(testdataset,batch_size = 100,shuffle = True,num_workers = num_workers,pin_memory = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num,epochs,lr):\n",
    "    start=time.time()\n",
    "    #結果を保存するディレクトリを作成\n",
    "    save_dir=f'save/{data_path}/patch_test/{num}'\n",
    "    os.makedirs(save_dir,exist_ok=True)\n",
    "\n",
    "\n",
    "    #モデルの初期化\n",
    "    model=SelfGCN()\n",
    "    model.to(device)\n",
    "    lossF=nn.CrossEntropyLoss()\n",
    "    optimizer=optim.AdamW(model.parameters(),lr=lr)\n",
    "\n",
    "    #情報保存用の変数の初期化\n",
    "    #トレーニング用\n",
    "    num_correct=0\n",
    "    num_tests=0\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    #テスト用\n",
    "    test_num_correct = 0\n",
    "    test_num_tests = 0\n",
    "    best_acc=0\n",
    "    test_acc_list = []\n",
    "\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        #トレーニング\n",
    "        model.train()\n",
    "        for batched_grapg, labels in traindataloader:\n",
    "            batched_grapg = batched_grapg.to(device)\n",
    "            labels = labels.to(device)\n",
    "            print(f'labels shape: {labels.shape}')\n",
    "            pred = model(batched_grapg,batched_grapg.ndata['f'])\n",
    "            loss=lossF(pred,labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "            num_tests += len(labels)\n",
    "        train_loss_list.append(loss.item())\n",
    "        train_acc_list.append(num_correct / num_tests)\n",
    "        #カウントリセット\n",
    "        num_correct=num_tests=0\n",
    "\n",
    "        #テスト\n",
    "        model.eval()\n",
    "        for tbatched_graph, tlabels in testdataloader:\n",
    "            tbatched_graph = tbatched_graph.to(device)\n",
    "            tlabels = tlabels.to(device)\n",
    "            tpred = model(tbatched_graph, tbatched_graph.ndata['f'])\n",
    "            test_num_correct += (tpred.argmax(1) == tlabels).sum().item()\n",
    "            test_num_tests += len(tlabels)\n",
    "\n",
    "        test_acc_list.append(test_num_correct/test_num_tests)\n",
    "        if best_acc < test_num_correct/test_num_tests:\n",
    "            best_acc = test_num_correct/test_num_tests\n",
    "            best_weight = model\n",
    "        #カウントリセット\n",
    "        test_num_correct=test_num_tests=0\n",
    "\n",
    "    #完全学習後の正答率の計算(推論)\n",
    "    with torch.no_grad():\n",
    "        #情報保存用の変数の初期化\n",
    "        #トレーニング用\n",
    "        num_correct=0\n",
    "        num_tests=0\n",
    "        save_train_acc=0\n",
    "        #テスト用\n",
    "        test_num_correct = 0\n",
    "        test_num_tests = 0\n",
    "        save_test_acc=0\n",
    "\n",
    "        #全トレーニングデータでの正答率計算\n",
    "        model.train()\n",
    "        for batched_graph, labels in traindataloader:\n",
    "            batched_graph = batched_graph.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred = model(batched_graph, batched_graph.ndata['f'])\n",
    "            num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "            num_tests += len(labels)\n",
    "        print('Training accuracy:', num_correct / num_tests)\n",
    "        save_train_acc=(num_correct / num_tests)\n",
    "\n",
    "        #全テストデータでの正答率\n",
    "        model.eval()\n",
    "        for batched_graph, labels in testdataloader:\n",
    "            batched_graph = batched_graph.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred = model(batched_graph, batched_graph.ndata['f'])\n",
    "            test_num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "            test_num_tests += len(labels)\n",
    "        print('Test accuracy:', test_num_correct / test_num_tests)\n",
    "        save_test_acc=(test_num_correct / test_num_tests)\n",
    "\n",
    "    #各エポックごとの損失・正答率の記録をモデルごとに.npy形式で保存\n",
    "    np.save(f'{save_dir}/train_loss_list',train_loss_list)\n",
    "    np.save(f'{save_dir}/train_acc_list',train_acc_list)\n",
    "    np.save(f'{save_dir}/test_acc_list',test_acc_list)\n",
    "    torch.save(model,f'{save_dir}/model_weight.pth')\n",
    "    torch.save(best_weight,f'{save_dir}/best_model_weight.pth')\n",
    "    #完全学習後のトレーニング・テストデータそれぞれの正答率を.yaml形式で保存\n",
    "    log={'train acc':save_train_acc,\n",
    "        'test acc':save_test_acc,\n",
    "        'epochs':epochs,\n",
    "        'best test acc':best_acc,\n",
    "        'date time':datetime.datetime.now(),\n",
    "        'run time':time.time() - start}\n",
    "        \n",
    "    with open(f'{save_dir}/acc_result.yaml',\"w\") as f:\n",
    "        yaml.dump(log,f)\n",
    "\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1回目\n",
      "labels shape: torch.Size([512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "DGLError",
     "evalue": "Expect number of features to match number of nodes (len(u)). Got 3 and 32768 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4349/3069634757.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleran_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{l+1}回目'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4349/3117169191.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num, epochs, lr)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'labels shape: {labels.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_grapg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatched_grapg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlossF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DGL/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4349/3487962401.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, n_feat)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DGL/lib/python3.8/site-packages/dgl/view.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, val)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;34m'The HeteroNodeDataView has only one node type. '\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;34m'please pass a tensor directly'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_n_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ntid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DGL/lib/python3.8/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36m_set_n_repr\u001b[0;34m(self, ntid, u, data)\u001b[0m\n\u001b[1;32m   4108\u001b[0m             \u001b[0mnfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4109\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnfeats\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4110\u001b[0;31m                 raise DGLError('Expect number of features to match number of nodes (len(u)).'\n\u001b[0m\u001b[1;32m   4111\u001b[0m                                ' Got %d and %d instead.' % (nfeats, num_nodes))\n\u001b[1;32m   4112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDGLError\u001b[0m: Expect number of features to match number of nodes (len(u)). Got 3 and 32768 instead."
     ]
    }
   ],
   "source": [
    "leran_num=2\n",
    "lr=0.0001\n",
    "epochs=2\n",
    "for l in range(leran_num):\n",
    "    print(f'{l+1}回目')\n",
    "    train(l,epochs,lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('DGL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b3aaad6f4b476a25b1278d44df95c159668e2b4a4f54834857505f20d9767c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
